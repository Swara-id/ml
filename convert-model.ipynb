{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.15\n",
      "  Using cached tensorflow-2.15.0-cp39-cp39-win_amd64.whl.metadata (3.6 kB)\n",
      "Collecting tensorflow-intel==2.15.0 (from tensorflow==2.15)\n",
      "  Using cached tensorflow_intel-2.15.0-cp39-cp39-win_amd64.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15) (18.1.1)\n",
      "Collecting ml-dtypes~=0.2.0 (from tensorflow-intel==2.15.0->tensorflow==2.15)\n",
      "  Using cached ml_dtypes-0.2.0-cp39-cp39-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15) (4.25.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15) (4.12.2)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15) (1.62.2)\n",
      "Collecting tensorboard<2.16,>=2.15 (from tensorflow-intel==2.15.0->tensorflow==2.15)\n",
      "  Using cached tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow==2.15) (2.15.0)\n",
      "Collecting keras<2.16,>=2.15.0 (from tensorflow-intel==2.15.0->tensorflow==2.15)\n",
      "  Using cached keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow==2.15) (0.41.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15) (2.29.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15) (3.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15) (3.0.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15) (2.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15) (7.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15) (2.1.5)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15) (3.18.1)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15) (0.6.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow==2.15) (3.2.2)\n",
      "Using cached tensorflow-2.15.0-cp39-cp39-win_amd64.whl (2.1 kB)\n",
      "Using cached tensorflow_intel-2.15.0-cp39-cp39-win_amd64.whl (300.8 MB)\n",
      "Using cached keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
      "Using cached ml_dtypes-0.2.0-cp39-cp39-win_amd64.whl (938 kB)\n",
      "Using cached tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n",
      "Installing collected packages: ml-dtypes, keras, tensorboard, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: ml-dtypes\n",
      "    Found existing installation: ml-dtypes 0.3.2\n",
      "    Uninstalling ml-dtypes-0.3.2:\n",
      "      Successfully uninstalled ml-dtypes-0.3.2\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 3.3.3\n",
      "    Uninstalling keras-3.3.3:\n",
      "      Successfully uninstalled keras-3.3.3\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.16.2\n",
      "    Uninstalling tensorboard-2.16.2:\n",
      "      Successfully uninstalled tensorboard-2.16.2\n",
      "  Attempting uninstall: tensorflow-intel\n",
      "    Found existing installation: tensorflow-intel 2.16.1\n",
      "    Uninstalling tensorflow-intel-2.16.1:\n",
      "      Successfully uninstalled tensorflow-intel-2.16.1\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.16.1\n",
      "    Uninstalling tensorflow-2.16.1:\n",
      "      Successfully uninstalled tensorflow-2.16.1\n",
      "Successfully installed keras-2.15.0 ml-dtypes-0.2.0 tensorboard-2.15.2 tensorflow-2.15.0 tensorflow-intel-2.15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\Lib\\site-packages\\~~_dtypes'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\Lib\\site-packages\\~.nsorflow'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorstore 0.1.58 requires ml-dtypes>=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Error when deserializing class 'InputLayer' using config={'batch_shape': [None, 63], 'dtype': 'float32', 'sparse': False, 'name': 'input_layer'}.\n\nException encountered: Unrecognized keyword arguments: ['batch_shape']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbundling-scaler-classification.h5\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Load the Keras model\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./models/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Convert the model to TensorFlow Lite format\u001b[39;00m\n\u001b[0;32m     10\u001b[0m converter \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mlite\u001b[38;5;241m.\u001b[39mTFLiteConverter\u001b[38;5;241m.\u001b[39mfrom_keras_model(model)\n",
      "File \u001b[1;32mc:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\keras\\src\\saving\\saving_api.py:262\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    260\u001b[0m             legacy_h5_format\u001b[38;5;241m.\u001b[39mload_weights_from_hdf5_group(f, model)\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 262\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    263\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile format not supported: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    264\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKeras 3 only supports V3 `.keras` and `.weights.h5` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    265\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiles, or legacy V1/V2 `.h5` files.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    266\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.config.is_traceback_filtering_enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_traceback_filtering_enabled\u001b[39m():\n\u001b[0;32m     62\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check if traceback filtering is enabled.\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \n\u001b[0;32m     64\u001b[0m \u001b[38;5;124;03m    Raw Keras tracebacks (also known as stack traces)\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    involve many internal frames, which can be\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;124;03m    challenging to read through, while not being actionable for end users.\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;124;03m    By default, Keras filters internal frames in most exceptions that it\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;124;03m    raises, to keep traceback short, readable, and focused on what's\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;124;03m    actionable for you (your own code).\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m \n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    See also `keras.config.enable_traceback_filtering()` and\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;124;03m    `keras.config.disable_traceback_filtering()`.\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \n\u001b[0;32m     74\u001b[0m \u001b[38;5;124;03m    If you have previously disabled traceback filtering via\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;124;03m    `keras.config.disable_traceback_filtering()`, you can re-enable it via\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;124;03m    `keras.config.enable_traceback_filtering()`.\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \n\u001b[0;32m     78\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;124;03m        Boolean, `True` if traceback filtering is enabled,\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;124;03m        and `False` otherwise.\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m global_state\u001b[38;5;241m.\u001b[39mget_global_attribute(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraceback_filtering\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\keras\\src\\engine\\base_layer.py:870\u001b[0m, in \u001b[0;36mLayer.from_config\u001b[1;34m(cls, config)\u001b[0m\n\u001b[0;32m    868\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig)\n\u001b[0;32m    869\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 870\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError when deserializing class \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m using \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mException encountered: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    873\u001b[0m     )\n",
      "\u001b[1;31mTypeError\u001b[0m: Error when deserializing class 'InputLayer' using config={'batch_shape': [None, 63], 'dtype': 'float32', 'sparse': False, 'name': 'input_layer'}.\n\nException encountered: Unrecognized keyword arguments: ['batch_shape']"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.15\n",
    "import tensorflow as tf\n",
    "\n",
    "model_name = 'bundling-scaler-classification.h5'\n",
    "\n",
    "# Load the Keras model\n",
    "model = tf.keras.models.load_model(f'./models/{model_name}')\n",
    "\n",
    "# Convert the model to TensorFlow Lite format\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the converted model to a file\n",
    "with open(f'{model_name}.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator StandardScaler from version 1.5.0 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "\n",
    "# Load the scikit-learn model\n",
    "model = joblib.load('scaler.pkl')\n",
    "\n",
    "# Define the initial type based on the model's input\n",
    "initial_type = [('float_input', FloatTensorType([None, model.n_features_in_]))]\n",
    "\n",
    "# Convert the model\n",
    "onnx_model = convert_sklearn(model, initial_types=initial_type)\n",
    "\n",
    "# Save the ONNX model to a file\n",
    "with open(\"model-scaling.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tensorflow==2.16 (from versions: 2.5.0, 2.5.1, 2.5.2, 2.5.3, 2.6.0rc0, 2.6.0rc1, 2.6.0rc2, 2.6.0, 2.6.1, 2.6.2, 2.6.3, 2.6.4, 2.6.5, 2.7.0rc0, 2.7.0rc1, 2.7.0, 2.7.1, 2.7.2, 2.7.3, 2.7.4, 2.8.0rc0, 2.8.0rc1, 2.8.0, 2.8.1, 2.8.2, 2.8.3, 2.8.4, 2.9.0rc0, 2.9.0rc1, 2.9.0rc2, 2.9.0, 2.9.1, 2.9.2, 2.9.3, 2.10.0rc0, 2.10.0rc1, 2.10.0rc2, 2.10.0rc3, 2.10.0, 2.10.1, 2.11.0rc0, 2.11.0rc1, 2.11.0rc2, 2.11.0, 2.11.1, 2.12.0rc0, 2.12.0rc1, 2.12.0, 2.12.1, 2.13.0rc0, 2.13.0rc1, 2.13.0rc2, 2.13.0, 2.13.1, 2.14.0rc0, 2.14.0rc1, 2.14.0, 2.14.1, 2.15.0rc0, 2.15.0rc1, 2.15.0, 2.15.1, 2.16.0rc0, 2.16.1)\n",
      "ERROR: No matching distribution found for tensorflow==2.16\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.16\n",
    "import tensorflow\n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'graph 137ab1c3cfa747768e429bded3e7d710 (\\n  %float_input[FLOAT, ?x63]\\n) {\\n  %variable = Scaler[offset = [0.45150750875473, 0.642758309841156, 7.68399814887744e-08, 0.456195503473282, 0.615919232368469, -0.00806499924510717, 0.461085915565491, 0.585133492946625, -0.0163439977914095, 0.464775830507278, 0.566622078418732, -0.0249864086508751, 0.465967267751694, 0.555129885673523, -0.0333644561469555, 0.457674860954285, 0.552962422370911, -0.0181095506995916, 0.462861806154251, 0.526998102664948, -0.0337809883058071, 0.465238958597183, 0.515335440635681, -0.0438422448933125, 0.466768056154251, 0.506061911582947, -0.0500885061919689, 0.456035077571869, 0.561384499073029, -0.0230625607073307, 0.464323312044144, 0.544810116291046, -0.0391807332634926, 0.466499388217926, 0.544645428657532, -0.0449655838310719, 0.466604292392731, 0.541296899318695, -0.0474227517843246, 0.454574823379517, 0.576087653636932, -0.0287716649472713, 0.462697982788086, 0.56383752822876, -0.0439836867153645, 0.464028179645538, 0.56522810459137, -0.0436041094362736, 0.463298290967941, 0.562856793403625, -0.0411524921655655, 0.453058242797852, 0.593948781490326, -0.0351745374500751, 0.459467142820358, 0.582936227321625, -0.0455420054495335, 0.460906475782394, 0.580933630466461, -0.0434656254947186, 0.460594654083252, 0.577194273471832, -0.0401736460626125], scale = [6.01230239868164, 6.89351606369019, 3255510, 6.65557193756104, 6.8673939704895, 73.1613464355469, 7.26610612869263, 6.84879350662231, 47.1730804443359, 7.52366733551025, 6.74168539047241, 36.0560073852539, 7.41282653808594, 6.5821795463562, 28.784387588501, 6.83987951278687, 6.75823163986206, 40.8679351806641, 7.1710033416748, 6.57956457138062, 29.2807788848877, 7.17928123474121, 6.39623975753784, 24.8622989654541, 7.02726268768311, 6.19739532470703, 22.557638168335, 6.57566976547241, 6.66885185241699, 41.9924201965332, 7.19708395004272, 6.4192943572998, 28.031379699707, 7.36503458023071, 6.16374349594116, 25.46950340271, 7.27834749221802, 5.92942428588867, 24.3843460083008, 6.3207893371582, 6.59324502944946, 40.084831237793, 6.91941547393799, 6.35312223434448, 27.5823612213135, 7.09983110427856, 6.11427927017212, 27.7162952423096, 7.07505321502686, 5.89653301239014, 27.9162540435791, 6.08962678909302, 6.53879594802856, 35.4933395385742, 6.50018358230591, 6.37509536743164, 27.7244930267334, 6.65413522720337, 6.22250318527222, 27.9610023498535, 6.65679597854614, 6.06524753570557, 28.1490993499756]](%float_input)\\n  return %variable\\n}'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import onnx\n",
    "\n",
    "# Load the ONNX model\n",
    "model = onnx.load(\"model-scaling.onnx\")\n",
    "\n",
    "# Check that the IR is well formed\n",
    "onnx.checker.check_model(model)\n",
    "\n",
    "# Print a Human readable representation of the graph\n",
    "onnx.helper.printable_graph(model.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 8\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m ort_session \u001b[38;5;241m=\u001b[39m ort\u001b[38;5;241m.\u001b[39mInferenceSession(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel-scaling.onnx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m outputs \u001b[38;5;241m=\u001b[39m ort_session\u001b[38;5;241m.\u001b[39mrun(\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m----> 8\u001b[0m     {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandn(\u001b[43mbatch_size\u001b[49m, channels, height, width)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)}\n\u001b[0;32m      9\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'batch_size' is not defined"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "\n",
    "ort_session = ort.InferenceSession('model-scaling.onnx')\n",
    "\n",
    "outputs = ort_session.run(\n",
    "    None,\n",
    "    {'input': np.random.randn(batch_size, channels, height, width).astype(np.float32)}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Unable to handle object of type <class 'ellipsis'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: 'ellipsis' object is not iterable",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m input_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m  \u001b[38;5;66;03m# Siapkan data input sesuai dengan kebutuhan model\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Lakukan inferensi\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43moutput_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Lakukan sesuatu dengan output yang dihasilkan\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(output)\n",
      "File \u001b[1;32mc:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py:220\u001b[0m, in \u001b[0;36mSession.run\u001b[1;34m(self, output_names, input_feed, run_options)\u001b[0m\n\u001b[0;32m    218\u001b[0m     output_names \u001b[38;5;241m=\u001b[39m [output\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs_meta]\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_feed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m C\u001b[38;5;241m.\u001b[39mEPFail \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_fallback:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Unable to handle object of type <class 'ellipsis'>"
     ]
    }
   ],
   "source": [
    "import onnxruntime\n",
    "\n",
    "# Tentukan path file model ONNX\n",
    "model_path = 'model-scaling.onnx'\n",
    "\n",
    "# Buat session untuk memuat model\n",
    "session = onnxruntime.InferenceSession(model_path)\n",
    "\n",
    "# Verifikasi nama input dan output dari model\n",
    "input_name = session.get_inputs()[0].name\n",
    "output_name = session.get_outputs()[0].name\n",
    "\n",
    "# Lakukan inferensi dengan memasukkan data input\n",
    "input_data = ...  # Siapkan data input sesuai dengan kebutuhan model\n",
    "\n",
    "# Lakukan inferensi\n",
    "output = session.run([output_name], {input_name: input_data})\n",
    "\n",
    "# Lakukan sesuatu dengan output yang dihasilkan\n",
    "print(output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bangkitcourse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
