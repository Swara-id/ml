{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import os\n",
    "import subprocess\n",
    "import requests\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data Testing Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./datasets/Testing-Image/11_N_92.jpg',\n",
       " './datasets/Testing-Image/11_q_.jpg',\n",
       " './datasets/Testing-Image/1_ibu_.jpg',\n",
       " './datasets/Testing-Image/87_kerja_1.jpg',\n",
       " './datasets/Testing-Image/8_kerja_1.jpg',\n",
       " './datasets/Testing-Image/8_malam_1.jpg',\n",
       " './datasets/Testing-Image/8_malam_2.jpg',\n",
       " './datasets/Testing-Image/8_siang_2.jpg',\n",
       " './datasets/Testing-Image/91_jawab_1.jpg',\n",
       " './datasets/Testing-Image/91_kantor_1.jpg',\n",
       " './datasets/Testing-Image/92_jawab_1.jpg',\n",
       " './datasets/Testing-Image/92_kantor_1.jpg',\n",
       " './datasets/Testing-Image/93_jawab_1.jpg',\n",
       " './datasets/Testing-Image/93_sore_1.jpg',\n",
       " './datasets/Testing-Image/95_bagaimana_1.jpg',\n",
       " './datasets/Testing-Image/95_bagaimana_2.jpg',\n",
       " './datasets/Testing-Image/96_bagaimana_1.jpg',\n",
       " './datasets/Testing-Image/96_besok_1.jpg',\n",
       " './datasets/Testing-Image/96_kemarin_2.jpg',\n",
       " './datasets/Testing-Image/96_nanti_1.jpg',\n",
       " './datasets/Testing-Image/97_lusa_1.jpg',\n",
       " './datasets/Testing-Image/97_nanti_1.jpg',\n",
       " './datasets/Testing-Image/98_sekarang_2.jpg',\n",
       " './datasets/Testing-Image/99_hari_ini_1.jpg',\n",
       " './datasets/Testing-Image/99_pagi_1.jpg',\n",
       " './datasets/Testing-Image/9_besok_1.jpg',\n",
       " './datasets/Testing-Image/9_besok_2.jpg',\n",
       " './datasets/Testing-Image/9_hari_ini1.jpg',\n",
       " './datasets/Testing-Image/9_hari_ini2.jpg',\n",
       " './datasets/Testing-Image/9_kantor_1.jpg',\n",
       " './datasets/Testing-Image/9_kemarin_1.jpg',\n",
       " './datasets/Testing-Image/9_kemarin_2.jpg',\n",
       " './datasets/Testing-Image/9_kerja_1.jpg',\n",
       " './datasets/Testing-Image/9_lusa_1.jpg',\n",
       " './datasets/Testing-Image/9_lusa_2.jpg',\n",
       " './datasets/Testing-Image/9_malam_2.jpg',\n",
       " './datasets/Testing-Image/9_nanti_1.jpg',\n",
       " './datasets/Testing-Image/9_pagi_1.jpg',\n",
       " './datasets/Testing-Image/9_pagi_2.jpg',\n",
       " './datasets/Testing-Image/9_sekarang_1.jpg',\n",
       " './datasets/Testing-Image/9_sekarang_2.jpg',\n",
       " './datasets/Testing-Image/9_siang_1.jpg',\n",
       " './datasets/Testing-Image/9_siang_2.jpg',\n",
       " './datasets/Testing-Image/9_sore_1.jpg',\n",
       " './datasets/Testing-Image/9_sore_2.jpg']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def list_jpg_png_files(directory):\n",
    "    jpg_png_files = []\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for filename in files:\n",
    "            if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "                file_path = os.path.join(root, filename)\n",
    "                file_path = file_path.replace('\\\\', '/')\n",
    "                jpg_png_files.append(file_path)\n",
    "    return jpg_png_files\n",
    "\n",
    "list_jpg_png_files('./datasets/Testing-Image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Static Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "source": [
    "def extract_hand_features(image_path):\n",
    "    mp_hands = mp.solutions.hands\n",
    "    hands = mp_hands.Hands(\n",
    "        static_image_mode=True, max_num_hands=1, min_detection_confidence=0.5\n",
    "    )\n",
    "\n",
    "    data = []\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(image_rgb)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            landmarks = []\n",
    "            for landmark in hand_landmarks.landmark:\n",
    "                landmarks.append(landmark.x)\n",
    "                landmarks.append(landmark.y)\n",
    "                landmarks.append(landmark.z)\n",
    "            data.append([os.path.basename(image_path)] + landmarks)\n",
    "\n",
    "    hands.close()\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "# sample_data = extract_hand_features(\"datasets/Testing-Image/0_Apa_1.jpg\")[0][1:]\n",
    "samples = []\n",
    "samples_path = []\n",
    "for file in list_jpg_png_files('./datasets/Testing-Image'):\n",
    "    samples_path.append(file)\n",
    "    samples += extract_hand_features(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./datasets/Testing-Image/11_N_92.jpg',\n",
       " './datasets/Testing-Image/11_q_.jpg',\n",
       " './datasets/Testing-Image/1_ibu_.jpg',\n",
       " './datasets/Testing-Image/87_kerja_1.jpg',\n",
       " './datasets/Testing-Image/8_kerja_1.jpg']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_path[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Test Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator StandardScaler from version 1.5.0 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator LabelEncoder from version 1.5.0 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "scaler = joblib.load(\"scaler.pkl\")\n",
    "\n",
    "for i in range(len(samples)):\n",
    "    # # with scaler \n",
    "    samples[i] = samples[i][1:]\n",
    "    samples[i] = np.array(samples[i]).reshape(1, -1)\n",
    "    samples[i] = scaler.transform(samples[i])\n",
    "\n",
    "    # without scaler\n",
    "    # samples[i] =  np.expand_dims(samples[i][1:], axis=0)\n",
    "\n",
    "label_encoder = joblib.load(\"label_encoder.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_33 (Dense)            (None, 64)                4096      \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 66)                2178      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8354 (32.63 KB)\n",
      "Trainable params: 8354 (32.63 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model_path = 'models/14-juni-1058am.h5'\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = ['A', 'Aku', 'Apa', 'B', 'Bagaimana', 'Baik', 'Bapak', 'Berapa',\n",
    "    'Besok', 'C', 'D', 'Dia', 'Dimana', 'E', 'F', 'G', 'H', 'Halo',\n",
    "    'Hari ini', 'I', 'Ibu', 'J', 'Jawab', 'K', 'Kalian', 'Kamu',\n",
    "    'Kantor', 'Kapan', 'Kemana', 'Kemarin', 'Kerja', 'L', 'Lelah',\n",
    "    'Lusa', 'M', 'Maaf', 'Makan', 'Malam', 'Mengapa', 'N', 'Nanti',\n",
    "    'O', 'P', 'Pagi', 'Q', 'R', 'S', 'Sabar', 'Sakit', 'Sama - sama',\n",
    "    'Sedih', 'Sekarang', 'Senang', 'Siang', 'Siapa', 'Sore', 'T',\n",
    "    'Terima kasih', 'Tidur', 'Tolong', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
    "\n",
    "def closest_label(input_word):\n",
    "    global class_labels\n",
    "    def levenshtein_distance(s1, s2):\n",
    "        if len(s1) < len(s2):\n",
    "            return levenshtein_distance(s2, s1)\n",
    "        if len(s2) == 0:\n",
    "            return len(s1)\n",
    "        \n",
    "        previous_row = range(len(s2) + 1)\n",
    "        for i, c1 in enumerate(s1):\n",
    "            current_row = [i + 1]\n",
    "            for j, c2 in enumerate(s2):\n",
    "                insertions = previous_row[j + 1] + 1\n",
    "                deletions = current_row[j] + 1\n",
    "                substitutions = previous_row[j] + (c1 != c2)\n",
    "                current_row.append(min(insertions, deletions, substitutions))\n",
    "            previous_row = current_row\n",
    "        \n",
    "        return previous_row[-1]\n",
    "    \n",
    "    closest_label = None\n",
    "    min_distance = float('inf')\n",
    "    \n",
    "    for label in class_labels:\n",
    "        if input_word.lower() in label.lower() and len(label) >= len(input_word):\n",
    "            distance = levenshtein_distance(input_word.lower(), label.lower())\n",
    "            if distance < min_distance:\n",
    "                min_distance = distance\n",
    "                closest_label = label\n",
    "    \n",
    "    return closest_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kata 'nanti' paling mendekati label: 'Nanti'\n"
     ]
    }
   ],
   "source": [
    "# Contoh penggunaan\n",
    "input_word = 'nanti'\n",
    "closest = closest_label(input_word)\n",
    "print(f\"Kata '{input_word}' paling mendekati label: '{closest}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nanti'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"9_nanti_1\".split('_')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted ./datasets/Testing-Image/11_N_92.jpg\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "==> True | T:N|P:N\n",
      "predicted ./datasets/Testing-Image/11_q_.jpg\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "==> True | T:Q|P:Q\n",
      "predicted ./datasets/Testing-Image/1_ibu_.jpg\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "==> True | T:Ibu|P:Ibu\n",
      "predicted ./datasets/Testing-Image/87_kerja_1.jpg\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "==> True | T:Kerja|P:Kerja\n",
      "predicted ./datasets/Testing-Image/8_kerja_1.jpg\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "==> True | T:Kerja|P:Kerja\n",
      "predicted ./datasets/Testing-Image/8_malam_1.jpg\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "==> True | T:Malam|P:Malam\n",
      "predicted ./datasets/Testing-Image/8_malam_2.jpg\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "==> True | T:Malam|P:Malam\n",
      "predicted ./datasets/Testing-Image/8_siang_2.jpg\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "==> True | T:Siang|P:Siang\n",
      "predicted ./datasets/Testing-Image/91_jawab_1.jpg\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "==> True | T:Jawab|P:Jawab\n",
      "predicted ./datasets/Testing-Image/91_kantor_1.jpg\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "==> True | T:Kantor|P:Kantor\n",
      "predicted ./datasets/Testing-Image/92_jawab_1.jpg\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "==> True | T:Jawab|P:Jawab\n",
      "predicted ./datasets/Testing-Image/92_kantor_1.jpg\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "==> True | T:Kantor|P:Kantor\n",
      "predicted ./datasets/Testing-Image/93_jawab_1.jpg\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "==> True | T:Jawab|P:Jawab\n",
      "predicted ./datasets/Testing-Image/93_sore_1.jpg\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "==> True | T:Sore|P:Sore\n",
      "predicted ./datasets/Testing-Image/95_bagaimana_1.jpg\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "==> True | T:Bagaimana|P:Bagaimana\n",
      "predicted ./datasets/Testing-Image/95_bagaimana_2.jpg\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "==> True | T:Bagaimana|P:Bagaimana\n",
      "predicted ./datasets/Testing-Image/96_bagaimana_1.jpg\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "==> True | T:Bagaimana|P:Bagaimana\n",
      "predicted ./datasets/Testing-Image/96_besok_1.jpg\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "==> True | T:Besok|P:Besok\n",
      "predicted ./datasets/Testing-Image/96_kemarin_2.jpg\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "==> None | T:Kemarin|P:Senang\n",
      "predicted ./datasets/Testing-Image/96_nanti_1.jpg\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "==> True | T:Nanti|P:Nanti\n",
      "predicted ./datasets/Testing-Image/97_lusa_1.jpg\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "==> True | T:Lusa|P:Lusa\n",
      "predicted ./datasets/Testing-Image/97_nanti_1.jpg\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "==> True | T:Nanti|P:Nanti\n",
      "predicted ./datasets/Testing-Image/98_sekarang_2.jpg\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "==> True | T:Sekarang|P:Sekarang\n",
      "predicted ./datasets/Testing-Image/99_hari_ini_1.jpg\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "==> True | T:Hari ini|P:Hari ini\n",
      "predicted ./datasets/Testing-Image/99_pagi_1.jpg\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "==> True | T:Pagi|P:Pagi\n",
      "predicted ./datasets/Testing-Image/9_besok_1.jpg\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "==> True | T:Besok|P:Besok\n",
      "predicted ./datasets/Testing-Image/9_besok_2.jpg\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "==> True | T:Besok|P:Besok\n",
      "predicted ./datasets/Testing-Image/9_hari_ini1.jpg\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "==> True | T:Hari ini|P:Hari ini\n",
      "predicted ./datasets/Testing-Image/9_hari_ini2.jpg\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "==> True | T:Hari ini|P:Hari ini\n",
      "predicted ./datasets/Testing-Image/9_kantor_1.jpg\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "==> True | T:Kantor|P:Kantor\n",
      "predicted ./datasets/Testing-Image/9_kemarin_1.jpg\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "==> True | T:Kemarin|P:Kemarin\n",
      "predicted ./datasets/Testing-Image/9_kemarin_2.jpg\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "==> True | T:Kemarin|P:Kemarin\n",
      "predicted ./datasets/Testing-Image/9_kerja_1.jpg\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "==> True | T:Kerja|P:Kerja\n",
      "predicted ./datasets/Testing-Image/9_lusa_1.jpg\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "==> True | T:Lusa|P:Lusa\n",
      "predicted ./datasets/Testing-Image/9_lusa_2.jpg\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "==> True | T:Lusa|P:Lusa\n",
      "predicted ./datasets/Testing-Image/9_malam_2.jpg\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "==> True | T:Malam|P:Malam\n",
      "predicted ./datasets/Testing-Image/9_nanti_1.jpg\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "==> True | T:Nanti|P:Nanti\n",
      "predicted ./datasets/Testing-Image/9_pagi_1.jpg\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "==> True | T:Pagi|P:Pagi\n",
      "predicted ./datasets/Testing-Image/9_pagi_2.jpg\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "==> True | T:Pagi|P:Pagi\n",
      "predicted ./datasets/Testing-Image/9_sekarang_1.jpg\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "==> True | T:Sekarang|P:Sekarang\n",
      "predicted ./datasets/Testing-Image/9_sekarang_2.jpg\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "==> True | T:Sekarang|P:Sekarang\n",
      "predicted ./datasets/Testing-Image/9_siang_1.jpg\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "==> True | T:Siang|P:Siang\n",
      "predicted ./datasets/Testing-Image/9_siang_2.jpg\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "==> True | T:Siang|P:Siang\n",
      "predicted ./datasets/Testing-Image/9_sore_1.jpg\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "==> True | T:Sore|P:Sore\n",
      "predicted ./datasets/Testing-Image/9_sore_2.jpg\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "==> True | T:Sore|P:Sore\n",
      "Done Predict 45 data with 44 True and 1 False\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "log_entries = []\n",
    "true = 0\n",
    "false = 0\n",
    "\n",
    "for i in range(len(samples)):\n",
    "    print(f\"predicted {samples_path[i]}\")\n",
    "    prediction = model.predict(samples[i])\n",
    "    prediction = np.argmax(prediction, axis=1)\n",
    "    prediction = class_labels[prediction[0]]\n",
    "    \n",
    "    label = samples_path[i].split('_')\n",
    "    if prediction == 'senang':\n",
    "        print(label)\n",
    "    label = label[1]\n",
    "    \n",
    "    label = closest_label(label)\n",
    "    \n",
    "    status = None\n",
    "    if label != None:\n",
    "        if label == prediction:\n",
    "            status = 'True'\n",
    "            true += 1\n",
    "        else:\n",
    "            staus = 'False'\n",
    "            false += 1\n",
    "    \n",
    "    # Append log entry to the list\n",
    "    log_entries.append({\n",
    "        'samples_path': samples_path,\n",
    "        'status': status,\n",
    "        'true_value': label,\n",
    "        'predicted_value': prediction\n",
    "    })\n",
    "    print(f'==> {status} | T:{label}|P:{prediction}')\n",
    "\n",
    "print(f\"Done Predict {true+false} data with {true} True and {false} False\")            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>samples_path</th>\n",
       "      <th>status</th>\n",
       "      <th>true_value</th>\n",
       "      <th>predicted_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[./datasets/Testing-Image/11_N_92.jpg, ./datas...</td>\n",
       "      <td>True</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[./datasets/Testing-Image/11_N_92.jpg, ./datas...</td>\n",
       "      <td>True</td>\n",
       "      <td>Q</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[./datasets/Testing-Image/11_N_92.jpg, ./datas...</td>\n",
       "      <td>True</td>\n",
       "      <td>Ibu</td>\n",
       "      <td>Ibu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[./datasets/Testing-Image/11_N_92.jpg, ./datas...</td>\n",
       "      <td>True</td>\n",
       "      <td>Kerja</td>\n",
       "      <td>Kerja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[./datasets/Testing-Image/11_N_92.jpg, ./datas...</td>\n",
       "      <td>True</td>\n",
       "      <td>Kerja</td>\n",
       "      <td>Kerja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[./datasets/Testing-Image/11_N_92.jpg, ./datas...</td>\n",
       "      <td>True</td>\n",
       "      <td>Malam</td>\n",
       "      <td>Malam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[./datasets/Testing-Image/11_N_92.jpg, ./datas...</td>\n",
       "      <td>True</td>\n",
       "      <td>Malam</td>\n",
       "      <td>Malam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[./datasets/Testing-Image/11_N_92.jpg, ./datas...</td>\n",
       "      <td>True</td>\n",
       "      <td>Siang</td>\n",
       "      <td>Siang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[./datasets/Testing-Image/11_N_92.jpg, ./datas...</td>\n",
       "      <td>True</td>\n",
       "      <td>Jawab</td>\n",
       "      <td>Jawab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[./datasets/Testing-Image/11_N_92.jpg, ./datas...</td>\n",
       "      <td>True</td>\n",
       "      <td>Kantor</td>\n",
       "      <td>Kantor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[./datasets/Testing-Image/11_N_92.jpg, ./datas...</td>\n",
       "      <td>True</td>\n",
       "      <td>Jawab</td>\n",
       "      <td>Jawab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[./datasets/Testing-Image/11_N_92.jpg, ./datas...</td>\n",
       "      <td>True</td>\n",
       "      <td>Kantor</td>\n",
       "      <td>Kantor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[./datasets/Testing-Image/11_N_92.jpg, ./datas...</td>\n",
       "      <td>True</td>\n",
       "      <td>Jawab</td>\n",
       "      <td>Jawab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[./datasets/Testing-Image/11_N_92.jpg, ./datas...</td>\n",
       "      <td>True</td>\n",
       "      <td>Sore</td>\n",
       "      <td>Sore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[./datasets/Testing-Image/11_N_92.jpg, ./datas...</td>\n",
       "      <td>True</td>\n",
       "      <td>Bagaimana</td>\n",
       "      <td>Bagaimana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[./datasets/Testing-Image/11_N_92.jpg, ./datas...</td>\n",
       "      <td>True</td>\n",
       "      <td>Bagaimana</td>\n",
       "      <td>Bagaimana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[./datasets/Testing-Image/11_N_92.jpg, ./datas...</td>\n",
       "      <td>True</td>\n",
       "      <td>Bagaimana</td>\n",
       "      <td>Bagaimana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[./datasets/Testing-Image/11_N_92.jpg, ./datas...</td>\n",
       "      <td>True</td>\n",
       "      <td>Besok</td>\n",
       "      <td>Besok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[./datasets/Testing-Image/11_N_92.jpg, ./datas...</td>\n",
       "      <td>None</td>\n",
       "      <td>Kemarin</td>\n",
       "      <td>Senang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[./datasets/Testing-Image/11_N_92.jpg, ./datas...</td>\n",
       "      <td>True</td>\n",
       "      <td>Nanti</td>\n",
       "      <td>Nanti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[./datasets/Testing-Image/11_N_92.jpg, ./datas...</td>\n",
       "      <td>True</td>\n",
       "      <td>Lusa</td>\n",
       "      <td>Lusa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[./datasets/Testing-Image/11_N_92.jpg, ./datas...</td>\n",
       "      <td>True</td>\n",
       "      <td>Nanti</td>\n",
       "      <td>Nanti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[./datasets/Testing-Image/11_N_92.jpg, ./datas...</td>\n",
       "      <td>True</td>\n",
       "      <td>Sekarang</td>\n",
       "      <td>Sekarang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[./datasets/Testing-Image/11_N_92.jpg, ./datas...</td>\n",
       "      <td>True</td>\n",
       "      <td>Hari ini</td>\n",
       "      <td>Hari ini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[./datasets/Testing-Image/11_N_92.jpg, ./datas...</td>\n",
       "      <td>True</td>\n",
       "      <td>Pagi</td>\n",
       "      <td>Pagi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[./datasets/Testing-Image/11_N_92.jpg, ./datas...</td>\n",
       "      <td>True</td>\n",
       "      <td>Besok</td>\n",
       "      <td>Besok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[./datasets/Testing-Image/11_N_92.jpg, ./datas...</td>\n",
       "      <td>True</td>\n",
       "      <td>Besok</td>\n",
       "      <td>Besok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[./datasets/Testing-Image/11_N_92.jpg, ./datas...</td>\n",
       "      <td>True</td>\n",
       "      <td>Hari ini</td>\n",
       "      <td>Hari ini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[./datasets/Testing-Image/11_N_92.jpg, ./datas...</td>\n",
       "      <td>True</td>\n",
       "      <td>Hari ini</td>\n",
       "      <td>Hari ini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[./datasets/Testing-Image/11_N_92.jpg, ./datas...</td>\n",
       "      <td>True</td>\n",
       "      <td>Kantor</td>\n",
       "      <td>Kantor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[./datasets/Testing-Image/11_N_92.jpg, ./datas...</td>\n",
       "      <td>True</td>\n",
       "      <td>Kemarin</td>\n",
       "      <td>Kemarin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[./datasets/Testing-Image/11_N_92.jpg, ./datas...</td>\n",
       "      <td>True</td>\n",
       "      <td>Kemarin</td>\n",
       "      <td>Kemarin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[./datasets/Testing-Image/11_N_92.jpg, ./datas...</td>\n",
       "      <td>True</td>\n",
       "      <td>Kerja</td>\n",
       "      <td>Kerja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[./datasets/Testing-Image/11_N_92.jpg, ./datas...</td>\n",
       "      <td>True</td>\n",
       "      <td>Lusa</td>\n",
       "      <td>Lusa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[./datasets/Testing-Image/11_N_92.jpg, ./datas...</td>\n",
       "      <td>True</td>\n",
       "      <td>Lusa</td>\n",
       "      <td>Lusa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[./datasets/Testing-Image/11_N_92.jpg, ./datas...</td>\n",
       "      <td>True</td>\n",
       "      <td>Malam</td>\n",
       "      <td>Malam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[./datasets/Testing-Image/11_N_92.jpg, ./datas...</td>\n",
       "      <td>True</td>\n",
       "      <td>Nanti</td>\n",
       "      <td>Nanti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[./datasets/Testing-Image/11_N_92.jpg, ./datas...</td>\n",
       "      <td>True</td>\n",
       "      <td>Pagi</td>\n",
       "      <td>Pagi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[./datasets/Testing-Image/11_N_92.jpg, ./datas...</td>\n",
       "      <td>True</td>\n",
       "      <td>Pagi</td>\n",
       "      <td>Pagi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[./datasets/Testing-Image/11_N_92.jpg, ./datas...</td>\n",
       "      <td>True</td>\n",
       "      <td>Sekarang</td>\n",
       "      <td>Sekarang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[./datasets/Testing-Image/11_N_92.jpg, ./datas...</td>\n",
       "      <td>True</td>\n",
       "      <td>Sekarang</td>\n",
       "      <td>Sekarang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[./datasets/Testing-Image/11_N_92.jpg, ./datas...</td>\n",
       "      <td>True</td>\n",
       "      <td>Siang</td>\n",
       "      <td>Siang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[./datasets/Testing-Image/11_N_92.jpg, ./datas...</td>\n",
       "      <td>True</td>\n",
       "      <td>Siang</td>\n",
       "      <td>Siang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[./datasets/Testing-Image/11_N_92.jpg, ./datas...</td>\n",
       "      <td>True</td>\n",
       "      <td>Sore</td>\n",
       "      <td>Sore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[./datasets/Testing-Image/11_N_92.jpg, ./datas...</td>\n",
       "      <td>True</td>\n",
       "      <td>Sore</td>\n",
       "      <td>Sore</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         samples_path status true_value  \\\n",
       "0   [./datasets/Testing-Image/11_N_92.jpg, ./datas...   True          N   \n",
       "1   [./datasets/Testing-Image/11_N_92.jpg, ./datas...   True          Q   \n",
       "2   [./datasets/Testing-Image/11_N_92.jpg, ./datas...   True        Ibu   \n",
       "3   [./datasets/Testing-Image/11_N_92.jpg, ./datas...   True      Kerja   \n",
       "4   [./datasets/Testing-Image/11_N_92.jpg, ./datas...   True      Kerja   \n",
       "5   [./datasets/Testing-Image/11_N_92.jpg, ./datas...   True      Malam   \n",
       "6   [./datasets/Testing-Image/11_N_92.jpg, ./datas...   True      Malam   \n",
       "7   [./datasets/Testing-Image/11_N_92.jpg, ./datas...   True      Siang   \n",
       "8   [./datasets/Testing-Image/11_N_92.jpg, ./datas...   True      Jawab   \n",
       "9   [./datasets/Testing-Image/11_N_92.jpg, ./datas...   True     Kantor   \n",
       "10  [./datasets/Testing-Image/11_N_92.jpg, ./datas...   True      Jawab   \n",
       "11  [./datasets/Testing-Image/11_N_92.jpg, ./datas...   True     Kantor   \n",
       "12  [./datasets/Testing-Image/11_N_92.jpg, ./datas...   True      Jawab   \n",
       "13  [./datasets/Testing-Image/11_N_92.jpg, ./datas...   True       Sore   \n",
       "14  [./datasets/Testing-Image/11_N_92.jpg, ./datas...   True  Bagaimana   \n",
       "15  [./datasets/Testing-Image/11_N_92.jpg, ./datas...   True  Bagaimana   \n",
       "16  [./datasets/Testing-Image/11_N_92.jpg, ./datas...   True  Bagaimana   \n",
       "17  [./datasets/Testing-Image/11_N_92.jpg, ./datas...   True      Besok   \n",
       "18  [./datasets/Testing-Image/11_N_92.jpg, ./datas...   None    Kemarin   \n",
       "19  [./datasets/Testing-Image/11_N_92.jpg, ./datas...   True      Nanti   \n",
       "20  [./datasets/Testing-Image/11_N_92.jpg, ./datas...   True       Lusa   \n",
       "21  [./datasets/Testing-Image/11_N_92.jpg, ./datas...   True      Nanti   \n",
       "22  [./datasets/Testing-Image/11_N_92.jpg, ./datas...   True   Sekarang   \n",
       "23  [./datasets/Testing-Image/11_N_92.jpg, ./datas...   True   Hari ini   \n",
       "24  [./datasets/Testing-Image/11_N_92.jpg, ./datas...   True       Pagi   \n",
       "25  [./datasets/Testing-Image/11_N_92.jpg, ./datas...   True      Besok   \n",
       "26  [./datasets/Testing-Image/11_N_92.jpg, ./datas...   True      Besok   \n",
       "27  [./datasets/Testing-Image/11_N_92.jpg, ./datas...   True   Hari ini   \n",
       "28  [./datasets/Testing-Image/11_N_92.jpg, ./datas...   True   Hari ini   \n",
       "29  [./datasets/Testing-Image/11_N_92.jpg, ./datas...   True     Kantor   \n",
       "30  [./datasets/Testing-Image/11_N_92.jpg, ./datas...   True    Kemarin   \n",
       "31  [./datasets/Testing-Image/11_N_92.jpg, ./datas...   True    Kemarin   \n",
       "32  [./datasets/Testing-Image/11_N_92.jpg, ./datas...   True      Kerja   \n",
       "33  [./datasets/Testing-Image/11_N_92.jpg, ./datas...   True       Lusa   \n",
       "34  [./datasets/Testing-Image/11_N_92.jpg, ./datas...   True       Lusa   \n",
       "35  [./datasets/Testing-Image/11_N_92.jpg, ./datas...   True      Malam   \n",
       "36  [./datasets/Testing-Image/11_N_92.jpg, ./datas...   True      Nanti   \n",
       "37  [./datasets/Testing-Image/11_N_92.jpg, ./datas...   True       Pagi   \n",
       "38  [./datasets/Testing-Image/11_N_92.jpg, ./datas...   True       Pagi   \n",
       "39  [./datasets/Testing-Image/11_N_92.jpg, ./datas...   True   Sekarang   \n",
       "40  [./datasets/Testing-Image/11_N_92.jpg, ./datas...   True   Sekarang   \n",
       "41  [./datasets/Testing-Image/11_N_92.jpg, ./datas...   True      Siang   \n",
       "42  [./datasets/Testing-Image/11_N_92.jpg, ./datas...   True      Siang   \n",
       "43  [./datasets/Testing-Image/11_N_92.jpg, ./datas...   True       Sore   \n",
       "44  [./datasets/Testing-Image/11_N_92.jpg, ./datas...   True       Sore   \n",
       "\n",
       "   predicted_value  \n",
       "0                N  \n",
       "1                Q  \n",
       "2              Ibu  \n",
       "3            Kerja  \n",
       "4            Kerja  \n",
       "5            Malam  \n",
       "6            Malam  \n",
       "7            Siang  \n",
       "8            Jawab  \n",
       "9           Kantor  \n",
       "10           Jawab  \n",
       "11          Kantor  \n",
       "12           Jawab  \n",
       "13            Sore  \n",
       "14       Bagaimana  \n",
       "15       Bagaimana  \n",
       "16       Bagaimana  \n",
       "17           Besok  \n",
       "18          Senang  \n",
       "19           Nanti  \n",
       "20            Lusa  \n",
       "21           Nanti  \n",
       "22        Sekarang  \n",
       "23        Hari ini  \n",
       "24            Pagi  \n",
       "25           Besok  \n",
       "26           Besok  \n",
       "27        Hari ini  \n",
       "28        Hari ini  \n",
       "29          Kantor  \n",
       "30         Kemarin  \n",
       "31         Kemarin  \n",
       "32           Kerja  \n",
       "33            Lusa  \n",
       "34            Lusa  \n",
       "35           Malam  \n",
       "36           Nanti  \n",
       "37            Pagi  \n",
       "38            Pagi  \n",
       "39        Sekarang  \n",
       "40        Sekarang  \n",
       "41           Siang  \n",
       "42           Siang  \n",
       "43            Sore  \n",
       "44            Sore  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_logs = pd.DataFrame(log_entries)\n",
    "df_logs.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "predicted_class_index = np.argmax(prediction)\n",
    "print(predicted_class_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_labels = ['A', 'Aku', 'Apa', 'B', 'Bagaimana', 'Baik', 'Bapak', 'Berapa',\n",
    "       'Besok', 'C', 'D', 'Dia', 'Dimana', 'E', 'F', 'G', 'H', 'Halo',\n",
    "       'Hari ini', 'I', 'Ibu', 'J', 'Jawab', 'K', 'Kalian', 'Kamu',\n",
    "       'Kantor', 'Kapan', 'Kemana', 'Kemarin', 'Kerja', 'L', 'Lelah',\n",
    "       'Lusa', 'M', 'Maaf', 'Makan', 'Malam', 'Mengapa', 'N', 'Nanti',\n",
    "       'O', 'P', 'Pagi', 'Q', 'R', 'S', 'Sabar', 'Sakit', 'Sama - sama',\n",
    "       'Sedih', 'Sekarang', 'Senang', 'Siang', 'Siapa', 'Sore', 'T',\n",
    "       'Terima kasih', 'Tidur', 'Tolong', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
    "\n",
    "\n",
    "predicted_class = class_labels[predicted_class_index]\n",
    "predicted_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DIEEEEEEEEEEEEEEE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function For Testing Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bangkitcourse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
