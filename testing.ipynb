{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import os\n",
    "import subprocess\n",
    "import requests\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data Testing Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./datasets/Testing-Image/11_N_92.jpg',\n",
       " './datasets/Testing-Image/11_q_.jpg',\n",
       " './datasets/Testing-Image/1_ibu_.jpg',\n",
       " './datasets/Testing-Image/87_kerja_1.jpg',\n",
       " './datasets/Testing-Image/8_kerja_1.jpg',\n",
       " './datasets/Testing-Image/8_malam_1.jpg',\n",
       " './datasets/Testing-Image/8_malam_2.jpg',\n",
       " './datasets/Testing-Image/8_siang_2.jpg',\n",
       " './datasets/Testing-Image/91_jawab_1.jpg',\n",
       " './datasets/Testing-Image/91_kantor_1.jpg',\n",
       " './datasets/Testing-Image/92_jawab_1.jpg',\n",
       " './datasets/Testing-Image/92_kantor_1.jpg',\n",
       " './datasets/Testing-Image/93_jawab_1.jpg',\n",
       " './datasets/Testing-Image/93_sore_1.jpg',\n",
       " './datasets/Testing-Image/95_bagaimana_1.jpg',\n",
       " './datasets/Testing-Image/95_bagaimana_2.jpg',\n",
       " './datasets/Testing-Image/96_bagaimana_1.jpg',\n",
       " './datasets/Testing-Image/96_besok_1.jpg',\n",
       " './datasets/Testing-Image/96_kemarin_2.jpg',\n",
       " './datasets/Testing-Image/96_nanti_1.jpg',\n",
       " './datasets/Testing-Image/97_lusa_1.jpg',\n",
       " './datasets/Testing-Image/97_nanti_1.jpg',\n",
       " './datasets/Testing-Image/98_sekarang_2.jpg',\n",
       " './datasets/Testing-Image/99_hari_ini_1.jpg',\n",
       " './datasets/Testing-Image/99_pagi_1.jpg',\n",
       " './datasets/Testing-Image/9_besok_1.jpg',\n",
       " './datasets/Testing-Image/9_besok_2.jpg',\n",
       " './datasets/Testing-Image/9_hari_ini1.jpg',\n",
       " './datasets/Testing-Image/9_hari_ini2.jpg',\n",
       " './datasets/Testing-Image/9_kantor_1.jpg',\n",
       " './datasets/Testing-Image/9_kemarin_1.jpg',\n",
       " './datasets/Testing-Image/9_kemarin_2.jpg',\n",
       " './datasets/Testing-Image/9_kerja_1.jpg',\n",
       " './datasets/Testing-Image/9_lusa_1.jpg',\n",
       " './datasets/Testing-Image/9_lusa_2.jpg',\n",
       " './datasets/Testing-Image/9_malam_2.jpg',\n",
       " './datasets/Testing-Image/9_nanti_1.jpg',\n",
       " './datasets/Testing-Image/9_pagi_1.jpg',\n",
       " './datasets/Testing-Image/9_pagi_2.jpg',\n",
       " './datasets/Testing-Image/9_sekarang_1.jpg',\n",
       " './datasets/Testing-Image/9_sekarang_2.jpg',\n",
       " './datasets/Testing-Image/9_siang_1.jpg',\n",
       " './datasets/Testing-Image/9_siang_2.jpg',\n",
       " './datasets/Testing-Image/9_sore_1.jpg',\n",
       " './datasets/Testing-Image/9_sore_2.jpg']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def list_jpg_png_files(directory):\n",
    "    jpg_png_files = []\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for filename in files:\n",
    "            if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "                file_path = os.path.join(root, filename)\n",
    "                file_path = file_path.replace('\\\\', '/')\n",
    "                jpg_png_files.append(file_path)\n",
    "    return jpg_png_files\n",
    "\n",
    "list_jpg_png_files('./datasets/Testing-Image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Static Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "source": [
    "def extract_hand_features(image_path):\n",
    "    mp_hands = mp.solutions.hands\n",
    "    hands = mp_hands.Hands(\n",
    "        static_image_mode=True, max_num_hands=1, min_detection_confidence=0.5\n",
    "    )\n",
    "\n",
    "    data = []\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(image_rgb)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            landmarks = []\n",
    "            for landmark in hand_landmarks.landmark:\n",
    "                landmarks.append(landmark.x)\n",
    "                landmarks.append(landmark.y)\n",
    "                landmarks.append(landmark.z)\n",
    "            data.append([os.path.basename(image_path)] + landmarks)\n",
    "\n",
    "    hands.close()\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "# sample_data = extract_hand_features(\"datasets/Testing-Image/0_Apa_1.jpg\")[0][1:]\n",
    "samples = []\n",
    "samples_path = []\n",
    "for file in list_jpg_png_files('./datasets/Testing-Image'):\n",
    "    samples_path.append(file)\n",
    "    samples += extract_hand_features(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./datasets/Testing-Image/11_N_92.jpg',\n",
       " './datasets/Testing-Image/11_q_.jpg',\n",
       " './datasets/Testing-Image/1_ibu_.jpg',\n",
       " './datasets/Testing-Image/87_kerja_1.jpg',\n",
       " './datasets/Testing-Image/8_kerja_1.jpg']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_path[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Test Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator StandardScaler from version 1.5.0 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\whisn\\anaconda3\\envs\\bangkitcourse\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator LabelEncoder from version 1.5.0 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "scaler = joblib.load(\"scaler.pkl\")\n",
    "\n",
    "for i in range(len(samples)):\n",
    "    # # with scaler \n",
    "    samples[i] = samples[i][1:]\n",
    "    samples[i] = np.array(samples[i]).reshape(1, -1)\n",
    "    samples[i] = scaler.transform(samples[i])\n",
    "\n",
    "    # without scaler\n",
    "    # samples[i] =  np.expand_dims(samples[i][1:], axis=0)\n",
    "\n",
    "label_encoder = joblib.load(\"label_encoder.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_33 (Dense)            (None, 64)                4096      \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 66)                2178      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8354 (32.63 KB)\n",
      "Trainable params: 8354 (32.63 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model_path = 'models/14-juni-1058am.h5'\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = ['A', 'Aku', 'Apa', 'B', 'Bagaimana', 'Baik', 'Bapak', 'Berapa',\n",
    "    'Besok', 'C', 'D', 'Dia', 'Dimana', 'E', 'F', 'G', 'H', 'Halo',\n",
    "    'Hari ini', 'I', 'Ibu', 'J', 'Jawab', 'K', 'Kalian', 'Kamu',\n",
    "    'Kantor', 'Kapan', 'Kemana', 'Kemarin', 'Kerja', 'L', 'Lelah',\n",
    "    'Lusa', 'M', 'Maaf', 'Makan', 'Malam', 'Mengapa', 'N', 'Nanti',\n",
    "    'O', 'P', 'Pagi', 'Q', 'R', 'S', 'Sabar', 'Sakit', 'Sama - sama',\n",
    "    'Sedih', 'Sekarang', 'Senang', 'Siang', 'Siapa', 'Sore', 'T',\n",
    "    'Terima kasih', 'Tidur', 'Tolong', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
    "\n",
    "def closest_label(input_word):\n",
    "    global class_labels\n",
    "    def levenshtein_distance(s1, s2):\n",
    "        if len(s1) < len(s2):\n",
    "            return levenshtein_distance(s2, s1)\n",
    "        if len(s2) == 0:\n",
    "            return len(s1)\n",
    "        \n",
    "        previous_row = range(len(s2) + 1)\n",
    "        for i, c1 in enumerate(s1):\n",
    "            current_row = [i + 1]\n",
    "            for j, c2 in enumerate(s2):\n",
    "                insertions = previous_row[j + 1] + 1\n",
    "                deletions = current_row[j] + 1\n",
    "                substitutions = previous_row[j] + (c1 != c2)\n",
    "                current_row.append(min(insertions, deletions, substitutions))\n",
    "            previous_row = current_row\n",
    "        \n",
    "        return previous_row[-1]\n",
    "    \n",
    "    closest_label = None\n",
    "    min_distance = float('inf')\n",
    "    \n",
    "    for label in class_labels:\n",
    "        if input_word.lower() in label.lower() and len(label) >= len(input_word):\n",
    "            distance = levenshtein_distance(input_word.lower(), label.lower())\n",
    "            if distance < min_distance:\n",
    "                min_distance = distance\n",
    "                closest_label = label\n",
    "    \n",
    "    return closest_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kata 'nanti' paling mendekati label: 'Nanti'\n"
     ]
    }
   ],
   "source": [
    "# Contoh penggunaan\n",
    "input_word = 'nanti'\n",
    "closest = closest_label(input_word)\n",
    "print(f\"Kata '{input_word}' paling mendekati label: '{closest}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nanti'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"9_nanti_1\".split('_')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"kemarin\" == \"senang\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted ./datasets/Testing-Image/11_N_92.jpg\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "==> True | T:N|P:N\n",
      "predicted ./datasets/Testing-Image/11_q_.jpg\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "==> True | T:Q|P:Q\n",
      "predicted ./datasets/Testing-Image/1_ibu_.jpg\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "==> True | T:Ibu|P:Ibu\n",
      "predicted ./datasets/Testing-Image/87_kerja_1.jpg\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "==> True | T:Kerja|P:Kerja\n",
      "predicted ./datasets/Testing-Image/8_kerja_1.jpg\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "==> True | T:Kerja|P:Kerja\n",
      "predicted ./datasets/Testing-Image/8_malam_1.jpg\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "==> True | T:Malam|P:Malam\n",
      "predicted ./datasets/Testing-Image/8_malam_2.jpg\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "==> True | T:Malam|P:Malam\n",
      "predicted ./datasets/Testing-Image/8_siang_2.jpg\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "==> True | T:Siang|P:Siang\n",
      "predicted ./datasets/Testing-Image/91_jawab_1.jpg\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "==> True | T:Jawab|P:Jawab\n",
      "predicted ./datasets/Testing-Image/91_kantor_1.jpg\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "==> True | T:Kantor|P:Kantor\n",
      "predicted ./datasets/Testing-Image/92_jawab_1.jpg\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "==> True | T:Jawab|P:Jawab\n",
      "predicted ./datasets/Testing-Image/92_kantor_1.jpg\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "==> True | T:Kantor|P:Kantor\n",
      "predicted ./datasets/Testing-Image/93_jawab_1.jpg\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "==> True | T:Jawab|P:Jawab\n",
      "predicted ./datasets/Testing-Image/93_sore_1.jpg\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "==> True | T:Sore|P:Sore\n",
      "predicted ./datasets/Testing-Image/95_bagaimana_1.jpg\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "==> True | T:Bagaimana|P:Bagaimana\n",
      "predicted ./datasets/Testing-Image/95_bagaimana_2.jpg\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "==> True | T:Bagaimana|P:Bagaimana\n",
      "predicted ./datasets/Testing-Image/96_bagaimana_1.jpg\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "==> True | T:Bagaimana|P:Bagaimana\n",
      "predicted ./datasets/Testing-Image/96_besok_1.jpg\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "==> True | T:Besok|P:Besok\n",
      "predicted ./datasets/Testing-Image/96_kemarin_2.jpg\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "==> False | T:Kemarin|P:Senang\n",
      "predicted ./datasets/Testing-Image/96_nanti_1.jpg\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "==> True | T:Nanti|P:Nanti\n",
      "predicted ./datasets/Testing-Image/97_lusa_1.jpg\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "==> True | T:Lusa|P:Lusa\n",
      "predicted ./datasets/Testing-Image/97_nanti_1.jpg\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "==> True | T:Nanti|P:Nanti\n",
      "predicted ./datasets/Testing-Image/98_sekarang_2.jpg\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "==> True | T:Sekarang|P:Sekarang\n",
      "predicted ./datasets/Testing-Image/99_hari_ini_1.jpg\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "==> True | T:Hari ini|P:Hari ini\n",
      "predicted ./datasets/Testing-Image/99_pagi_1.jpg\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "==> True | T:Pagi|P:Pagi\n",
      "predicted ./datasets/Testing-Image/9_besok_1.jpg\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "==> True | T:Besok|P:Besok\n",
      "predicted ./datasets/Testing-Image/9_besok_2.jpg\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "==> True | T:Besok|P:Besok\n",
      "predicted ./datasets/Testing-Image/9_hari_ini1.jpg\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "==> True | T:Hari ini|P:Hari ini\n",
      "predicted ./datasets/Testing-Image/9_hari_ini2.jpg\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "==> True | T:Hari ini|P:Hari ini\n",
      "predicted ./datasets/Testing-Image/9_kantor_1.jpg\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "==> True | T:Kantor|P:Kantor\n",
      "predicted ./datasets/Testing-Image/9_kemarin_1.jpg\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "==> True | T:Kemarin|P:Kemarin\n",
      "predicted ./datasets/Testing-Image/9_kemarin_2.jpg\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "==> True | T:Kemarin|P:Kemarin\n",
      "predicted ./datasets/Testing-Image/9_kerja_1.jpg\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "==> True | T:Kerja|P:Kerja\n",
      "predicted ./datasets/Testing-Image/9_lusa_1.jpg\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "==> True | T:Lusa|P:Lusa\n",
      "predicted ./datasets/Testing-Image/9_lusa_2.jpg\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "==> True | T:Lusa|P:Lusa\n",
      "predicted ./datasets/Testing-Image/9_malam_2.jpg\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "==> True | T:Malam|P:Malam\n",
      "predicted ./datasets/Testing-Image/9_nanti_1.jpg\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "==> True | T:Nanti|P:Nanti\n",
      "predicted ./datasets/Testing-Image/9_pagi_1.jpg\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "==> True | T:Pagi|P:Pagi\n",
      "predicted ./datasets/Testing-Image/9_pagi_2.jpg\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "==> True | T:Pagi|P:Pagi\n",
      "predicted ./datasets/Testing-Image/9_sekarang_1.jpg\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "==> True | T:Sekarang|P:Sekarang\n",
      "predicted ./datasets/Testing-Image/9_sekarang_2.jpg\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "==> True | T:Sekarang|P:Sekarang\n",
      "predicted ./datasets/Testing-Image/9_siang_1.jpg\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "==> True | T:Siang|P:Siang\n",
      "predicted ./datasets/Testing-Image/9_siang_2.jpg\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "==> True | T:Siang|P:Siang\n",
      "predicted ./datasets/Testing-Image/9_sore_1.jpg\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "==> True | T:Sore|P:Sore\n",
      "predicted ./datasets/Testing-Image/9_sore_2.jpg\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "==> True | T:Sore|P:Sore\n",
      "Done Predict 45 data with 44 True and 1 False\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "log_entries = []\n",
    "true = 0\n",
    "false = 0\n",
    "\n",
    "for i in range(len(samples)):\n",
    "    print(f\"predicted {samples_path[i]}\")\n",
    "    prediction = model.predict(samples[i])\n",
    "    prediction = np.argmax(prediction, axis=1)\n",
    "    prediction = class_labels[prediction[0]]\n",
    "    \n",
    "    label = samples_path[i].split('_')\n",
    "    label = label[1]\n",
    "    \n",
    "    label = closest_label(label)\n",
    "    \n",
    "    status = None\n",
    "    if label != None:\n",
    "        if label == prediction:\n",
    "            status = 'True'\n",
    "            true += 1\n",
    "        else:\n",
    "            status = 'False'\n",
    "            false += 1\n",
    "    # else\n",
    "    # Append log entry to the list\n",
    "    log_entries.append({\n",
    "        'samples_path': samples_path[i],\n",
    "        'status': status,\n",
    "        'true_value': label,\n",
    "        'predicted_value': prediction\n",
    "    })\n",
    "    print(f'==> {status} | T:{label}|P:{prediction}')\n",
    "\n",
    "print(f\"Done Predict {true+false} data with {true} True and {false} False\")            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>samples_path</th>\n",
       "      <th>status</th>\n",
       "      <th>true_value</th>\n",
       "      <th>predicted_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./datasets/Testing-Image/11_N_92.jpg</td>\n",
       "      <td>True</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./datasets/Testing-Image/11_q_.jpg</td>\n",
       "      <td>True</td>\n",
       "      <td>Q</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./datasets/Testing-Image/1_ibu_.jpg</td>\n",
       "      <td>True</td>\n",
       "      <td>Ibu</td>\n",
       "      <td>Ibu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./datasets/Testing-Image/87_kerja_1.jpg</td>\n",
       "      <td>True</td>\n",
       "      <td>Kerja</td>\n",
       "      <td>Kerja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./datasets/Testing-Image/8_kerja_1.jpg</td>\n",
       "      <td>True</td>\n",
       "      <td>Kerja</td>\n",
       "      <td>Kerja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>./datasets/Testing-Image/8_malam_1.jpg</td>\n",
       "      <td>True</td>\n",
       "      <td>Malam</td>\n",
       "      <td>Malam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>./datasets/Testing-Image/8_malam_2.jpg</td>\n",
       "      <td>True</td>\n",
       "      <td>Malam</td>\n",
       "      <td>Malam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>./datasets/Testing-Image/8_siang_2.jpg</td>\n",
       "      <td>True</td>\n",
       "      <td>Siang</td>\n",
       "      <td>Siang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>./datasets/Testing-Image/91_jawab_1.jpg</td>\n",
       "      <td>True</td>\n",
       "      <td>Jawab</td>\n",
       "      <td>Jawab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>./datasets/Testing-Image/91_kantor_1.jpg</td>\n",
       "      <td>True</td>\n",
       "      <td>Kantor</td>\n",
       "      <td>Kantor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>./datasets/Testing-Image/92_jawab_1.jpg</td>\n",
       "      <td>True</td>\n",
       "      <td>Jawab</td>\n",
       "      <td>Jawab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>./datasets/Testing-Image/92_kantor_1.jpg</td>\n",
       "      <td>True</td>\n",
       "      <td>Kantor</td>\n",
       "      <td>Kantor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>./datasets/Testing-Image/93_jawab_1.jpg</td>\n",
       "      <td>True</td>\n",
       "      <td>Jawab</td>\n",
       "      <td>Jawab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>./datasets/Testing-Image/93_sore_1.jpg</td>\n",
       "      <td>True</td>\n",
       "      <td>Sore</td>\n",
       "      <td>Sore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>./datasets/Testing-Image/95_bagaimana_1.jpg</td>\n",
       "      <td>True</td>\n",
       "      <td>Bagaimana</td>\n",
       "      <td>Bagaimana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>./datasets/Testing-Image/95_bagaimana_2.jpg</td>\n",
       "      <td>True</td>\n",
       "      <td>Bagaimana</td>\n",
       "      <td>Bagaimana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>./datasets/Testing-Image/96_bagaimana_1.jpg</td>\n",
       "      <td>True</td>\n",
       "      <td>Bagaimana</td>\n",
       "      <td>Bagaimana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>./datasets/Testing-Image/96_besok_1.jpg</td>\n",
       "      <td>True</td>\n",
       "      <td>Besok</td>\n",
       "      <td>Besok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>./datasets/Testing-Image/96_kemarin_2.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>Kemarin</td>\n",
       "      <td>Senang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>./datasets/Testing-Image/96_nanti_1.jpg</td>\n",
       "      <td>True</td>\n",
       "      <td>Nanti</td>\n",
       "      <td>Nanti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>./datasets/Testing-Image/97_lusa_1.jpg</td>\n",
       "      <td>True</td>\n",
       "      <td>Lusa</td>\n",
       "      <td>Lusa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>./datasets/Testing-Image/97_nanti_1.jpg</td>\n",
       "      <td>True</td>\n",
       "      <td>Nanti</td>\n",
       "      <td>Nanti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>./datasets/Testing-Image/98_sekarang_2.jpg</td>\n",
       "      <td>True</td>\n",
       "      <td>Sekarang</td>\n",
       "      <td>Sekarang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>./datasets/Testing-Image/99_hari_ini_1.jpg</td>\n",
       "      <td>True</td>\n",
       "      <td>Hari ini</td>\n",
       "      <td>Hari ini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>./datasets/Testing-Image/99_pagi_1.jpg</td>\n",
       "      <td>True</td>\n",
       "      <td>Pagi</td>\n",
       "      <td>Pagi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>./datasets/Testing-Image/9_besok_1.jpg</td>\n",
       "      <td>True</td>\n",
       "      <td>Besok</td>\n",
       "      <td>Besok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>./datasets/Testing-Image/9_besok_2.jpg</td>\n",
       "      <td>True</td>\n",
       "      <td>Besok</td>\n",
       "      <td>Besok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>./datasets/Testing-Image/9_hari_ini1.jpg</td>\n",
       "      <td>True</td>\n",
       "      <td>Hari ini</td>\n",
       "      <td>Hari ini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>./datasets/Testing-Image/9_hari_ini2.jpg</td>\n",
       "      <td>True</td>\n",
       "      <td>Hari ini</td>\n",
       "      <td>Hari ini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>./datasets/Testing-Image/9_kantor_1.jpg</td>\n",
       "      <td>True</td>\n",
       "      <td>Kantor</td>\n",
       "      <td>Kantor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>./datasets/Testing-Image/9_kemarin_1.jpg</td>\n",
       "      <td>True</td>\n",
       "      <td>Kemarin</td>\n",
       "      <td>Kemarin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>./datasets/Testing-Image/9_kemarin_2.jpg</td>\n",
       "      <td>True</td>\n",
       "      <td>Kemarin</td>\n",
       "      <td>Kemarin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>./datasets/Testing-Image/9_kerja_1.jpg</td>\n",
       "      <td>True</td>\n",
       "      <td>Kerja</td>\n",
       "      <td>Kerja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>./datasets/Testing-Image/9_lusa_1.jpg</td>\n",
       "      <td>True</td>\n",
       "      <td>Lusa</td>\n",
       "      <td>Lusa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>./datasets/Testing-Image/9_lusa_2.jpg</td>\n",
       "      <td>True</td>\n",
       "      <td>Lusa</td>\n",
       "      <td>Lusa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>./datasets/Testing-Image/9_malam_2.jpg</td>\n",
       "      <td>True</td>\n",
       "      <td>Malam</td>\n",
       "      <td>Malam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>./datasets/Testing-Image/9_nanti_1.jpg</td>\n",
       "      <td>True</td>\n",
       "      <td>Nanti</td>\n",
       "      <td>Nanti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>./datasets/Testing-Image/9_pagi_1.jpg</td>\n",
       "      <td>True</td>\n",
       "      <td>Pagi</td>\n",
       "      <td>Pagi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>./datasets/Testing-Image/9_pagi_2.jpg</td>\n",
       "      <td>True</td>\n",
       "      <td>Pagi</td>\n",
       "      <td>Pagi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>./datasets/Testing-Image/9_sekarang_1.jpg</td>\n",
       "      <td>True</td>\n",
       "      <td>Sekarang</td>\n",
       "      <td>Sekarang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>./datasets/Testing-Image/9_sekarang_2.jpg</td>\n",
       "      <td>True</td>\n",
       "      <td>Sekarang</td>\n",
       "      <td>Sekarang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>./datasets/Testing-Image/9_siang_1.jpg</td>\n",
       "      <td>True</td>\n",
       "      <td>Siang</td>\n",
       "      <td>Siang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>./datasets/Testing-Image/9_siang_2.jpg</td>\n",
       "      <td>True</td>\n",
       "      <td>Siang</td>\n",
       "      <td>Siang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>./datasets/Testing-Image/9_sore_1.jpg</td>\n",
       "      <td>True</td>\n",
       "      <td>Sore</td>\n",
       "      <td>Sore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>./datasets/Testing-Image/9_sore_2.jpg</td>\n",
       "      <td>True</td>\n",
       "      <td>Sore</td>\n",
       "      <td>Sore</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   samples_path status true_value  \\\n",
       "0          ./datasets/Testing-Image/11_N_92.jpg   True          N   \n",
       "1            ./datasets/Testing-Image/11_q_.jpg   True          Q   \n",
       "2           ./datasets/Testing-Image/1_ibu_.jpg   True        Ibu   \n",
       "3       ./datasets/Testing-Image/87_kerja_1.jpg   True      Kerja   \n",
       "4        ./datasets/Testing-Image/8_kerja_1.jpg   True      Kerja   \n",
       "5        ./datasets/Testing-Image/8_malam_1.jpg   True      Malam   \n",
       "6        ./datasets/Testing-Image/8_malam_2.jpg   True      Malam   \n",
       "7        ./datasets/Testing-Image/8_siang_2.jpg   True      Siang   \n",
       "8       ./datasets/Testing-Image/91_jawab_1.jpg   True      Jawab   \n",
       "9      ./datasets/Testing-Image/91_kantor_1.jpg   True     Kantor   \n",
       "10      ./datasets/Testing-Image/92_jawab_1.jpg   True      Jawab   \n",
       "11     ./datasets/Testing-Image/92_kantor_1.jpg   True     Kantor   \n",
       "12      ./datasets/Testing-Image/93_jawab_1.jpg   True      Jawab   \n",
       "13       ./datasets/Testing-Image/93_sore_1.jpg   True       Sore   \n",
       "14  ./datasets/Testing-Image/95_bagaimana_1.jpg   True  Bagaimana   \n",
       "15  ./datasets/Testing-Image/95_bagaimana_2.jpg   True  Bagaimana   \n",
       "16  ./datasets/Testing-Image/96_bagaimana_1.jpg   True  Bagaimana   \n",
       "17      ./datasets/Testing-Image/96_besok_1.jpg   True      Besok   \n",
       "18    ./datasets/Testing-Image/96_kemarin_2.jpg  False    Kemarin   \n",
       "19      ./datasets/Testing-Image/96_nanti_1.jpg   True      Nanti   \n",
       "20       ./datasets/Testing-Image/97_lusa_1.jpg   True       Lusa   \n",
       "21      ./datasets/Testing-Image/97_nanti_1.jpg   True      Nanti   \n",
       "22   ./datasets/Testing-Image/98_sekarang_2.jpg   True   Sekarang   \n",
       "23   ./datasets/Testing-Image/99_hari_ini_1.jpg   True   Hari ini   \n",
       "24       ./datasets/Testing-Image/99_pagi_1.jpg   True       Pagi   \n",
       "25       ./datasets/Testing-Image/9_besok_1.jpg   True      Besok   \n",
       "26       ./datasets/Testing-Image/9_besok_2.jpg   True      Besok   \n",
       "27     ./datasets/Testing-Image/9_hari_ini1.jpg   True   Hari ini   \n",
       "28     ./datasets/Testing-Image/9_hari_ini2.jpg   True   Hari ini   \n",
       "29      ./datasets/Testing-Image/9_kantor_1.jpg   True     Kantor   \n",
       "30     ./datasets/Testing-Image/9_kemarin_1.jpg   True    Kemarin   \n",
       "31     ./datasets/Testing-Image/9_kemarin_2.jpg   True    Kemarin   \n",
       "32       ./datasets/Testing-Image/9_kerja_1.jpg   True      Kerja   \n",
       "33        ./datasets/Testing-Image/9_lusa_1.jpg   True       Lusa   \n",
       "34        ./datasets/Testing-Image/9_lusa_2.jpg   True       Lusa   \n",
       "35       ./datasets/Testing-Image/9_malam_2.jpg   True      Malam   \n",
       "36       ./datasets/Testing-Image/9_nanti_1.jpg   True      Nanti   \n",
       "37        ./datasets/Testing-Image/9_pagi_1.jpg   True       Pagi   \n",
       "38        ./datasets/Testing-Image/9_pagi_2.jpg   True       Pagi   \n",
       "39    ./datasets/Testing-Image/9_sekarang_1.jpg   True   Sekarang   \n",
       "40    ./datasets/Testing-Image/9_sekarang_2.jpg   True   Sekarang   \n",
       "41       ./datasets/Testing-Image/9_siang_1.jpg   True      Siang   \n",
       "42       ./datasets/Testing-Image/9_siang_2.jpg   True      Siang   \n",
       "43        ./datasets/Testing-Image/9_sore_1.jpg   True       Sore   \n",
       "44        ./datasets/Testing-Image/9_sore_2.jpg   True       Sore   \n",
       "\n",
       "   predicted_value  \n",
       "0                N  \n",
       "1                Q  \n",
       "2              Ibu  \n",
       "3            Kerja  \n",
       "4            Kerja  \n",
       "5            Malam  \n",
       "6            Malam  \n",
       "7            Siang  \n",
       "8            Jawab  \n",
       "9           Kantor  \n",
       "10           Jawab  \n",
       "11          Kantor  \n",
       "12           Jawab  \n",
       "13            Sore  \n",
       "14       Bagaimana  \n",
       "15       Bagaimana  \n",
       "16       Bagaimana  \n",
       "17           Besok  \n",
       "18          Senang  \n",
       "19           Nanti  \n",
       "20            Lusa  \n",
       "21           Nanti  \n",
       "22        Sekarang  \n",
       "23        Hari ini  \n",
       "24            Pagi  \n",
       "25           Besok  \n",
       "26           Besok  \n",
       "27        Hari ini  \n",
       "28        Hari ini  \n",
       "29          Kantor  \n",
       "30         Kemarin  \n",
       "31         Kemarin  \n",
       "32           Kerja  \n",
       "33            Lusa  \n",
       "34            Lusa  \n",
       "35           Malam  \n",
       "36           Nanti  \n",
       "37            Pagi  \n",
       "38            Pagi  \n",
       "39        Sekarang  \n",
       "40        Sekarang  \n",
       "41           Siang  \n",
       "42           Siang  \n",
       "43            Sore  \n",
       "44            Sore  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "df_logs = pd.DataFrame(log_entries)\n",
    "df_logs.head(100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bangkitcourse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
