{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e3ef80b-05ab-442e-bdbb-f04abb47883a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mediapipe as mp\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d7069a-3bca-4b95-8884-6fead9c8212c",
   "metadata": {},
   "source": [
    "# 1. Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c670f84c-939c-4ac3-83bd-994166f49da9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for label in os.listdir(folder):\n",
    "        dir_path = os.path.join(folder, label)\n",
    "        for image in os.listdir(dir_path):\n",
    "            img_path = os.path.join(dir_path, image)\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.resize(img, (240, 240))  # Resize all images to 540x960\n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "    return images, labels\n",
    "\n",
    "dataset_folder = \"../datasets/Filtered Raw Images\"\n",
    "images, labels = load_images_from_folder(dataset_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06973889-7a74-4e24-8ae9-51528320efb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4557"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f10d07af-e46f-431f-9690-37547ce853f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4557, 960, 540, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4557,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ensure images and labels are arrays\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "display(images.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80d82d13-635d-4053-a5ab-32a3dcc7fc27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3645"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "912"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "display(len(X_train), len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a82a855-82f3-4149-a50c-b0b8197ec10b",
   "metadata": {},
   "source": [
    "# 2. Mediapipe Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b39fccb5-5dbf-450b-ab9e-143567a6877d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0 = 0.7126893997192383\n",
      "y0 = 0.5958437919616699\n",
      "z0 = -2.822761757670378e-07\n",
      "x1 = 0.7068435549736023\n",
      "y1 = 0.5655960440635681\n",
      "z1 = 0.0005654096021316946\n",
      "x2 = 0.6719934940338135\n",
      "y2 = 0.5394784808158875\n",
      "z2 = -0.006420113146305084\n",
      "x3 = 0.6180561780929565\n",
      "y3 = 0.5358845591545105\n",
      "z3 = -0.014703338965773582\n",
      "x4 = 0.5825240612030029\n",
      "y4 = 0.5438482165336609\n",
      "z4 = -0.024391671642661095\n",
      "x5 = 0.6728824973106384\n",
      "y5 = 0.5193976759910583\n",
      "z5 = -0.014605844393372536\n",
      "x6 = 0.5981832146644592\n",
      "y6 = 0.5157224535942078\n",
      "z6 = -0.0312117338180542\n",
      "x7 = 0.5640261769294739\n",
      "y7 = 0.5215676426887512\n",
      "z7 = -0.04208071902394295\n",
      "x8 = 0.5449411273002625\n",
      "y8 = 0.5251739025115967\n",
      "z8 = -0.04884830862283707\n",
      "x9 = 0.6578308343887329\n",
      "y9 = 0.5311128497123718\n",
      "z9 = -0.023794526234269142\n",
      "x10 = 0.5807985067367554\n",
      "y10 = 0.5289844870567322\n",
      "z10 = -0.03685164824128151\n",
      "x11 = 0.5745165348052979\n",
      "y11 = 0.5382302403450012\n",
      "z11 = -0.04019805043935776\n",
      "x12 = 0.579787015914917\n",
      "y12 = 0.5417948961257935\n",
      "z12 = -0.04272283613681793\n",
      "x13 = 0.6429769992828369\n",
      "y13 = 0.5467798113822937\n",
      "z13 = -0.032640404999256134\n",
      "x14 = 0.5789843797683716\n",
      "y14 = 0.5528262853622437\n",
      "z14 = -0.04570482671260834\n",
      "x15 = 0.5967677235603333\n",
      "y15 = 0.5628358125686646\n",
      "z15 = -0.04200568422675133\n",
      "x16 = 0.6191274523735046\n",
      "y16 = 0.5641025304794312\n",
      "z16 = -0.038860298693180084\n",
      "x17 = 0.6272186636924744\n",
      "y17 = 0.5645965933799744\n",
      "z17 = -0.04129447042942047\n",
      "x18 = 0.5860742330551147\n",
      "y18 = 0.5689784288406372\n",
      "z18 = -0.05166110396385193\n",
      "x19 = 0.6042731404304504\n",
      "y19 = 0.5764351487159729\n",
      "z19 = -0.04699654132127762\n",
      "x20 = 0.6247704029083252\n",
      "y20 = 0.5778875946998596\n",
      "z20 = -0.042351190000772476\n",
      "[0.7126893997192383, 0.5958437919616699, -2.822761757670378e-07, 0.7068435549736023, 0.5655960440635681, 0.0005654096021316946, 0.6719934940338135, 0.5394784808158875, -0.006420113146305084, 0.6180561780929565, 0.5358845591545105, -0.014703338965773582, 0.5825240612030029, 0.5438482165336609, -0.024391671642661095, 0.6728824973106384, 0.5193976759910583, -0.014605844393372536, 0.5981832146644592, 0.5157224535942078, -0.0312117338180542, 0.5640261769294739, 0.5215676426887512, -0.04208071902394295, 0.5449411273002625, 0.5251739025115967, -0.04884830862283707, 0.6578308343887329, 0.5311128497123718, -0.023794526234269142, 0.5807985067367554, 0.5289844870567322, -0.03685164824128151, 0.5745165348052979, 0.5382302403450012, -0.04019805043935776, 0.579787015914917, 0.5417948961257935, -0.04272283613681793, 0.6429769992828369, 0.5467798113822937, -0.032640404999256134, 0.5789843797683716, 0.5528262853622437, -0.04570482671260834, 0.5967677235603333, 0.5628358125686646, -0.04200568422675133, 0.6191274523735046, 0.5641025304794312, -0.038860298693180084, 0.6272186636924744, 0.5645965933799744, -0.04129447042942047, 0.5860742330551147, 0.5689784288406372, -0.05166110396385193, 0.6042731404304504, 0.5764351487159729, -0.04699654132127762, 0.6247704029083252, 0.5778875946998596, -0.042351190000772476]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Apps\\anaconda\\envs\\swara\\lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "source": [
    "mp_hands = mp.solutions.hands\n",
    "# Initialize hand landmark detection with specific parameters\n",
    "hands = mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5, max_num_hands=2)\n",
    "\n",
    "def detect_landmarks(image):\n",
    "    landmarks_coordinate = []\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(image_rgb)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            for idx, landmark in enumerate(hand_landmarks.landmark):\n",
    "                print(f'x{idx} = {landmark.x}')\n",
    "                landmarks_coordinate.append(landmark.x)\n",
    "                print(f'y{idx} = {landmark.y}')\n",
    "                landmarks_coordinate.append(landmark.y)\n",
    "                print(f'z{idx} = {landmark.z}')\n",
    "                landmarks_coordinate.append(landmark.z)\n",
    "    return landmarks_coordinate\n",
    "                \n",
    "\n",
    "# Example usage\n",
    "example_image = X_train[0]\n",
    "landmarks = detect_landmarks(example_image)\n",
    "print(landmarks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f37c528-d03d-4fe2-a4e3-d63c76f22ca0",
   "metadata": {},
   "source": [
    "# 3. Custom Layer untuk DNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ceff26-312b-4c2f-ad51-0f2a569cda65",
   "metadata": {},
   "source": [
    "## 3.1. Version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "3b0f1990-f4be-4e70-b6cc-bce5a39ff62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LandmarksDetector layer\n",
    "class LandmarksDetector(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(LandmarksDetector, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        all_landmarks_coordinate = []\n",
    "        for image in inputs:\n",
    "            skip = False\n",
    "            landmarks_coordinate = []\n",
    "            image = tf.cast(image, tf.uint8)\n",
    "            # image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image_rgb = image[..., ::-1]  # Convert BGR to RGB\n",
    "            image_rgb = tf.image.convert_image_dtype(image_rgb, dtype=tf.uint8)\n",
    "\n",
    "            #---------------------------------------------------------------------\n",
    "            results = hands.process(image_rgb.numpy())\n",
    "\n",
    "            if results.multi_hand_landmarks:\n",
    "                for hand_landmarks in results.multi_hand_landmarks:\n",
    "                    print(len(hand_landmarks.landmark))\n",
    "                    if len(hand_landmarks.landmark) == 21 or len(hand_landmarks.landmark) == 42:\n",
    "                        for idx, landmark in enumerate(hand_landmarks.landmark):\n",
    "                            landmarks_coordinate.append(landmark.x)\n",
    "                            landmarks_coordinate.append(landmark.y)\n",
    "                            landmarks_coordinate.append(landmark.z)\n",
    "                    else:\n",
    "                        skip = True\n",
    "                if len(landmarks_coordinate) > 63 and not skip:\n",
    "                    all_landmarks_coordinate.append(landmarks_coordinate[:63])\n",
    "                    all_landmarks_coordinate.append(landmarks_coordinate[63:])\n",
    "                elif not skip:\n",
    "                    all_landmarks_coordinate.append(landmarks_coordinate)\n",
    "        return tf.convert_to_tensor(all_landmarks_coordinate, dtype=tf.float32)\n",
    "        # return all_landmarks_coordinate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b771fb-8a35-4f39-9214-0b90e3a58030",
   "metadata": {},
   "source": [
    "## 3.2. Version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "9f4fd385-b2fa-406d-bde2-af0a255e4ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LandmarksDetectorV2(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(LandmarksDetectorV2, self).__init__(**kwargs)\n",
    "        self.holistic = mp.solutions.holistic.Holistic(static_image_mode=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        def get_landmarks(image):\n",
    "            image = tf.cast(image, tf.uint8)\n",
    "            image_rgb = image[..., ::-1]  # Convert BGR to RGB\n",
    "            image_rgb = tf.image.convert_image_dtype(image_rgb, dtype=tf.uint8)\n",
    "\n",
    "            def _get_landmarks(image_rgb_np):\n",
    "                results = self.holistic.process(image_rgb_np)\n",
    "                if results.pose_landmarks:\n",
    "                    landmarks = [(lm.x, lm.y, lm.z) for lm in results.pose_landmarks.landmark]\n",
    "                    return np.array(landmarks, dtype=np.float32).flatten()\n",
    "                else:\n",
    "                    return np.zeros(33 * 3, dtype=np.float32)\n",
    "\n",
    "            landmarks = tf.numpy_function(_get_landmarks, [image_rgb], tf.float32)\n",
    "            \n",
    "            return landmarks\n",
    "\n",
    "        landmarks = tf.map_fn(get_landmarks, inputs, dtype=tf.float32)\n",
    "        return landmarks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00d7630-3636-414e-af22-bbbb2d36bd52",
   "metadata": {},
   "source": [
    "## 3.3. Version 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec55709-6e4c-45c0-9d2b-4be82d36e31c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d153268-e62d-4e1b-8890-b40f6045c71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LandmarksDetectorV3(tf.keras.layers.Layer):\n",
    "    def __init__(self, scaler_path, **kwargs):\n",
    "        super(LandmarksDetectorV3, self).__init__(**kwargs)\n",
    "        self.mp_hands = mp.solutions.hands\n",
    "        self.hands = self.mp_hands.Hands()\n",
    "        self.scaler = joblib.load(scaler_path)  # Load the scaler\n",
    "\n",
    "    def call(self, inputs):\n",
    "        def get_landmarks(image):\n",
    "            image = tf.cast(image, tf.uint8)\n",
    "            image_rgb = image[..., ::-1]  # Convert BGR to RGB\n",
    "            image_rgb = tf.image.convert_image_dtype(image_rgb, dtype=tf.uint8)\n",
    "\n",
    "            def _get_landmarks(image_rgb_np):\n",
    "                results = self.hands.process(image_rgb_np)\n",
    "                landmarks_coordinate = np.zeros(63, dtype=np.float32)  # Fixed size array of zeros\n",
    "                if results.multi_hand_landmarks:\n",
    "                    hand_landmarks = results.multi_hand_landmarks[0]\n",
    "                    for idx, landmark in enumerate(hand_landmarks.landmark):\n",
    "                        if idx < 21:  # We only consider the first 21 landmarks\n",
    "                            landmarks_coordinate[idx * 3] = landmark.x\n",
    "                            landmarks_coordinate[idx * 3 + 1] = landmark.y\n",
    "                            landmarks_coordinate[idx * 3 + 2] = landmark.z\n",
    "                return landmarks_coordinate\n",
    "\n",
    "            landmarks = tf.numpy_function(_get_landmarks, [image_rgb], tf.float32)\n",
    "            landmarks.set_shape([63])  # Explicitly set the shape of the output tensor\n",
    "            return landmarks\n",
    "\n",
    "        landmarks = tf.map_fn(get_landmarks, inputs, dtype=tf.float32)\n",
    "        landmarks.set_shape([inputs.shape[0], 63])  # Explicitly set the shape of the output tensor\n",
    "\n",
    "        # Apply the scaler to the landmarks\n",
    "        def apply_scaler(landmarks_np):\n",
    "            return self.scaler.transform(landmarks_np.reshape(1, -1)).flatten()\n",
    "\n",
    "        scaled_landmarks = tf.numpy_function(apply_scaler, [landmarks], tf.float32)\n",
    "        scaled_landmarks.set_shape([inputs.shape[0], 63])  # Ensure the shape is correct after scaling\n",
    "\n",
    "        return scaled_landmarks\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], 63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb650c11-eca9-4053-bd11-590e8bc156bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10,  1,  1], dtype=uint8)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=uint8, numpy=array([ 1,  1, 10], dtype=uint8)>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = X_train[0][0][0]\n",
    "image_rgb = image[..., ::-1]  # Convert BGR to RGB\n",
    "image_rgb = tf.image.convert_image_dtype(image_rgb, dtype=tf.uint8)\n",
    "\n",
    "display(image, image_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5bd3a298-5bd6-4857-8866-8c047952ae6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'> (10, 960, 540, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Apps\\anaconda\\envs\\swara\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:371: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  return py_builtins.overload_of(f)(*args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Landmarks Shape: (10, 63)\n",
      "Extracted Landmarks type: <class 'numpy.ndarray'>\n",
      "Extracted Landmarks: [[ 6.50429189e-01  7.65751958e-01  5.50131404e-07  6.11938357e-01\n",
      "   7.33383536e-01 -1.35441273e-02  5.35249114e-01  7.22817481e-01\n",
      "  -2.79281605e-02  4.65442121e-01  7.31120050e-01 -3.91142108e-02\n",
      "   4.14158881e-01  7.32273340e-01 -5.05237058e-02  5.13722479e-01\n",
      "   7.15550065e-01 -5.68768531e-02  4.23396856e-01  7.09593713e-01\n",
      "  -8.50891545e-02  3.65506083e-01  7.05735862e-01 -9.82945263e-02\n",
      "   3.19084823e-01  7.02936769e-01 -1.04017541e-01  5.05995333e-01\n",
      "   7.45270610e-01 -5.81868589e-02  4.07936394e-01  7.56167054e-01\n",
      "  -8.43833536e-02  3.41932833e-01  7.66833425e-01 -9.30837318e-02\n",
      "   2.91373193e-01  7.76903272e-01 -9.70777795e-02  5.10187984e-01\n",
      "   7.75411189e-01 -5.61929680e-02  4.48203862e-01  7.83267856e-01\n",
      "  -7.50082582e-02  4.74850684e-01  7.78621018e-01 -5.97336926e-02\n",
      "   5.01763761e-01  7.75916219e-01 -4.30598781e-02  5.23284853e-01\n",
      "   8.01351249e-01 -5.47791123e-02  4.73276764e-01  8.00730944e-01\n",
      "  -6.20542802e-02  4.95798916e-01  7.95901060e-01 -4.32284512e-02\n",
      "   5.17879248e-01  7.94146419e-01 -2.44699549e-02]\n",
      " [ 2.00046882e-01  7.62508154e-01  2.96013098e-07  2.54809231e-01\n",
      "   7.86722064e-01  4.34049813e-04  3.11822861e-01  7.88549244e-01\n",
      "   1.46128354e-04  3.50474238e-01  7.89354324e-01 -4.03226726e-03\n",
      "   3.83433968e-01  7.91498423e-01 -7.44951470e-03  3.33289355e-01\n",
      "   7.48187721e-01  8.76795873e-03  3.85895461e-01  7.66190827e-01\n",
      "  -6.21644221e-03  4.22634900e-01  7.78614819e-01 -1.97783746e-02\n",
      "   4.53008324e-01  7.86484838e-01 -2.96991710e-02  3.24695319e-01\n",
      "   7.47849345e-01 -2.62305583e-03  3.85139018e-01  7.66928017e-01\n",
      "  -1.69114973e-02  4.21857923e-01  7.78277457e-01 -2.83362921e-02\n",
      "   4.57557112e-01  7.86125898e-01 -3.61586288e-02  3.11988860e-01\n",
      "   7.55178094e-01 -1.62271187e-02  3.72519732e-01  7.71120310e-01\n",
      "  -2.98693273e-02  4.08875406e-01  7.80377448e-01 -3.45961526e-02\n",
      "   4.40949023e-01  7.86452234e-01 -3.66609171e-02  2.98860371e-01\n",
      "   7.67693698e-01 -3.09280921e-02  3.43478709e-01  7.75304377e-01\n",
      "  -4.00747061e-02  3.74409497e-01  7.80019939e-01 -4.16074507e-02\n",
      "   4.01225150e-01  7.84422696e-01 -4.20858786e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 4.99494195e-01  7.04785466e-01 -3.49952423e-08  5.44945538e-01\n",
      "   7.05605686e-01  2.48935702e-03  5.82986414e-01  6.97282553e-01\n",
      "   6.93112263e-04  6.08755469e-01  6.85801983e-01 -2.68910732e-03\n",
      "   6.25670135e-01  6.75521255e-01 -7.52008287e-03  5.88867784e-01\n",
      "   7.07123876e-01 -7.89762754e-03  6.26527786e-01  6.97060764e-01\n",
      "  -1.78895462e-02  6.47335172e-01  6.89227164e-01 -2.50109807e-02\n",
      "   6.63347721e-01  6.82698369e-01 -2.98116840e-02  5.79872191e-01\n",
      "   7.02456772e-01 -1.50680272e-02  6.20733857e-01  6.91581964e-01\n",
      "  -2.40889285e-02  6.43253148e-01  6.82461858e-01 -2.97164433e-02\n",
      "   6.60763621e-01  6.74909234e-01 -3.44819017e-02  5.67550182e-01\n",
      "   6.96746528e-01 -2.21611522e-02  6.04867995e-01  6.85190916e-01\n",
      "  -2.98422594e-02  6.26716971e-01  6.75756454e-01 -3.38621885e-02\n",
      "   6.42665029e-01  6.67827904e-01 -3.72078083e-02  5.51960051e-01\n",
      "   6.90178335e-01 -2.88291648e-02  5.79406500e-01  6.80789411e-01\n",
      "  -3.47341970e-02  5.98006666e-01  6.74111366e-01 -3.70936692e-02\n",
      "   6.13043189e-01  6.68083429e-01 -3.94394174e-02]\n",
      " [ 5.96885800e-01  7.01031983e-01 -3.46888555e-07  5.39749503e-01\n",
      "   6.94623411e-01 -1.98538974e-02  4.93866891e-01  6.76950872e-01\n",
      "  -4.49563228e-02  4.82242107e-01  6.53202891e-01 -6.84678704e-02\n",
      "   4.85927224e-01  6.35223567e-01 -9.24228504e-02  4.80126828e-01\n",
      "   6.96595073e-01 -5.83809838e-02  4.63687062e-01  6.61778450e-01\n",
      "  -8.91380310e-02  4.85724956e-01  6.37687564e-01 -1.10592373e-01\n",
      "   5.03708959e-01  6.21669650e-01 -1.22285940e-01  5.17589629e-01\n",
      "   7.00905263e-01 -5.97992614e-02  5.04391551e-01  6.66903317e-01\n",
      "  -7.38785192e-02  5.35647929e-01  6.45025551e-01 -7.57013559e-02\n",
      "   5.51347375e-01  6.30547583e-01 -8.05830583e-02  5.62671661e-01\n",
      "   7.02336550e-01 -6.09938130e-02  5.50400257e-01  6.70008540e-01\n",
      "  -7.07741231e-02  5.72984278e-01  6.56856239e-01 -5.92633523e-02\n",
      "   5.84829390e-01  6.50236011e-01 -5.28238043e-02  6.09318733e-01\n",
      "   6.99665070e-01 -6.50175586e-02  5.97357571e-01  6.73954964e-01\n",
      "  -7.57098645e-02  6.11674607e-01  6.63721740e-01 -6.58094510e-02\n",
      "   6.20499611e-01  6.60109043e-01 -5.69394678e-02]\n",
      " [ 5.37046194e-01  7.12157369e-01  5.41682255e-07  5.56719482e-01\n",
      "   6.76388860e-01  8.13816767e-03  5.43331802e-01  6.42802477e-01\n",
      "   6.63189730e-03  5.00362039e-01  6.24726772e-01  1.01807737e-03\n",
      "   4.68103081e-01  6.15642607e-01 -4.88325488e-03  5.46342731e-01\n",
      "   6.22731507e-01 -3.05373361e-03  5.21740139e-01  5.84338307e-01\n",
      "  -1.69722587e-02  5.15212357e-01  5.60691237e-01 -2.42383629e-02\n",
      "   5.11530519e-01  5.41073680e-01 -2.71401946e-02  5.16811728e-01\n",
      "   6.24309957e-01 -1.38308667e-02  4.96909440e-01  5.82934022e-01\n",
      "  -2.64675636e-02  4.90681261e-01  5.57448268e-01 -3.21389772e-02\n",
      "   4.87353563e-01  5.35387278e-01 -3.40204164e-02  4.86023307e-01\n",
      "   6.31858170e-01 -2.33269949e-02  4.46425408e-01  6.14225745e-01\n",
      "  -3.32241654e-02  4.47948664e-01  6.29783332e-01 -2.71722712e-02\n",
      "   4.57881838e-01  6.41056538e-01 -1.84755269e-02  4.54758108e-01\n",
      "   6.43529058e-01 -3.25666964e-02  4.27295506e-01  6.33837283e-01\n",
      "  -3.46431769e-02  4.32620734e-01  6.46684051e-01 -2.44646631e-02\n",
      "   4.42367464e-01  6.55016303e-01 -1.39573095e-02]\n",
      " [ 6.25449061e-01  7.10849047e-01 -3.05959333e-07  5.99167466e-01\n",
      "   6.85908616e-01 -1.10808145e-02  6.00974321e-01  6.52837694e-01\n",
      "  -1.75710283e-02  6.22103214e-01  6.30603135e-01 -2.67769378e-02\n",
      "   6.40694737e-01  6.12907350e-01 -3.60711031e-02  6.64582968e-01\n",
      "   6.25880361e-01 -9.77565534e-03  6.95186853e-01  5.99900663e-01\n",
      "  -3.17411795e-02  7.20810711e-01  5.83583713e-01 -4.70453314e-02\n",
      "   7.45064378e-01  5.70954978e-01 -5.75797521e-02  6.97425485e-01\n",
      "   6.37356699e-01 -1.81234926e-02  6.68176234e-01  6.31460369e-01\n",
      "  -5.00495024e-02  6.36031747e-01  6.47716403e-01 -5.86962774e-02\n",
      "   6.24949276e-01  6.59201026e-01 -5.79958521e-02  7.17243373e-01\n",
      "   6.55206382e-01 -2.89256144e-02  6.78948164e-01  6.54543042e-01\n",
      "  -5.79400808e-02  6.49115443e-01  6.69390261e-01 -5.01554459e-02\n",
      "   6.41729534e-01  6.77396297e-01 -3.79336216e-02  7.30292439e-01\n",
      "   6.75990522e-01 -4.15082276e-02  6.96563125e-01  6.73014820e-01\n",
      "  -5.86664639e-02  6.68103158e-01  6.81560278e-01 -4.99292873e-02\n",
      "   6.58485651e-01  6.86957359e-01 -3.82230058e-02]\n",
      " [ 6.54216588e-01  7.48940170e-01 -3.68603253e-07  6.17619991e-01\n",
      "   7.31485248e-01 -2.43675392e-02  6.06468678e-01  7.01733947e-01\n",
      "  -4.19115908e-02  6.35669351e-01  6.85963988e-01 -5.92813604e-02\n",
      "   6.71095431e-01  6.80389583e-01 -7.60570467e-02  6.73964322e-01\n",
      "   6.66308701e-01 -3.95447686e-02  7.15261400e-01  6.36613905e-01\n",
      "  -6.49560541e-02  7.47798324e-01  6.24196231e-01 -8.17286596e-02\n",
      "   7.77799129e-01  6.14055037e-01 -9.41864625e-02  7.12530434e-01\n",
      "   6.76174641e-01 -4.19863760e-02  6.98565245e-01  6.84801042e-01\n",
      "  -7.93208107e-02  6.72436297e-01  7.03227818e-01 -8.75670314e-02\n",
      "   6.60437405e-01  7.13784456e-01 -8.66998285e-02  7.36876905e-01\n",
      "   6.92970097e-01 -4.64792587e-02  7.12622106e-01  7.03985929e-01\n",
      "  -7.77903795e-02  6.85083091e-01  7.18236148e-01 -6.96874261e-02\n",
      "   6.74322546e-01  7.24883318e-01 -5.81975468e-02  7.55287051e-01\n",
      "   7.11898267e-01 -5.39785922e-02  7.30769515e-01  7.20260978e-01\n",
      "  -7.35193938e-02  7.01500118e-01  7.30234981e-01 -6.64583221e-02\n",
      "   6.87504649e-01  7.34476924e-01 -5.61972037e-02]\n",
      " [ 1.65569842e-01  6.38717413e-01  4.74297764e-07  1.79523706e-01\n",
      "   6.05270147e-01 -1.58631988e-03  2.12030560e-01  5.77198744e-01\n",
      "  -1.61480103e-02  2.60536045e-01  5.65981805e-01 -3.38746011e-02\n",
      "   2.99859852e-01  5.69000006e-01 -5.03552519e-02  1.81347892e-01\n",
      "   5.52134573e-01 -2.72233002e-02  2.62942284e-01  5.41357636e-01\n",
      "  -4.76594865e-02  3.05201262e-01  5.44185340e-01 -5.85815124e-02\n",
      "   3.32885534e-01  5.47061265e-01 -6.52519464e-02  1.85364366e-01\n",
      "   5.69186211e-01 -4.01520059e-02  2.74299204e-01  5.57838023e-01\n",
      "  -5.77262528e-02  3.20791274e-01  5.57535887e-01 -6.14359975e-02\n",
      "   3.50611836e-01  5.57017267e-01 -6.55351654e-02  1.96029961e-01\n",
      "   5.88862538e-01 -5.30590750e-02  2.80410886e-01  5.83767653e-01\n",
      "  -6.85186088e-02  2.87858039e-01  5.92618346e-01 -6.45341873e-02\n",
      "   2.79078245e-01  5.98182797e-01 -6.10614382e-02  2.13787943e-01\n",
      "   6.08830690e-01 -6.66042045e-02  2.75686949e-01  6.02120817e-01\n",
      "  -7.23743290e-02  2.77885884e-01  6.06923580e-01 -6.53442666e-02\n",
      "   2.69965470e-01  6.09982073e-01 -6.02920428e-02]\n",
      " [ 5.97633243e-01  7.25916624e-01  4.31210083e-07  5.74081481e-01\n",
      "   6.97087765e-01 -9.82850697e-03  5.14241457e-01  6.78620934e-01\n",
      "  -1.58844497e-02  4.57953006e-01  6.82176709e-01 -2.07507182e-02\n",
      "   4.22401130e-01  6.94214106e-01 -2.63496749e-02  4.86690670e-01\n",
      "   6.72786951e-01 -2.83473432e-02  4.10791039e-01  6.62213445e-01\n",
      "  -4.50537801e-02  3.59942913e-01  6.55781865e-01 -5.30186519e-02\n",
      "   3.21438760e-01  6.51239991e-01 -5.63690662e-02  4.72530186e-01\n",
      "   6.93946600e-01 -3.07258517e-02  3.92782480e-01  7.01958179e-01\n",
      "  -4.77388203e-02  3.38921905e-01  7.07978904e-01 -5.60741425e-02\n",
      "   2.98616648e-01  7.10985184e-01 -5.99386357e-02  4.68255877e-01\n",
      "   7.17342436e-01 -3.17930318e-02  4.27522779e-01  7.33713686e-01\n",
      "  -4.77882326e-02  4.46590573e-01  7.36723483e-01 -4.51274365e-02\n",
      "   4.66726780e-01  7.33717978e-01 -3.82194445e-02  4.71534431e-01\n",
      "   7.40595818e-01 -3.33705097e-02  4.45068449e-01  7.51296818e-01\n",
      "  -4.19576764e-02  4.64055330e-01  7.53742456e-01 -3.40047181e-02\n",
      "   4.82293308e-01  7.51156569e-01 -2.40833201e-02]]\n"
     ]
    }
   ],
   "source": [
    "# Initialize MediaPipe Hands\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands()\n",
    "\n",
    "# Load an example image\n",
    "image = X_train[:10]\n",
    "# print(type(image), image.shape)\n",
    "\n",
    "# Expand dimensions to create a batch of size 1\n",
    "image_batch = tf.convert_to_tensor(image)\n",
    "# image_batch = tf.expand_dims(image, 0)\n",
    "print(type(image_batch), image_batch.shape)\n",
    "\n",
    "# Create an instance of the LandmarksDetector layer\n",
    "landmarks_detector = LandmarksDetectorV3()\n",
    "\n",
    "# Pass the image through the LandmarksDetector layer\n",
    "landmarks = landmarks_detector(image_batch)\n",
    "\n",
    "# Convert the landmarks tensor to a NumPy array for inspection\n",
    "# landmarks_array = landmarks\n",
    "landmarks_array = landmarks.numpy()\n",
    "\n",
    "# Print the shape of the extracted landmarks\n",
    "print(\"Extracted Landmarks Shape:\", landmarks_array.shape)\n",
    "print(\"Extracted Landmarks type:\", type(landmarks_array))\n",
    "print(\"Extracted Landmarks:\", landmarks_array)\n",
    "\n",
    "# Don't forget to close the hands instance\n",
    "hands.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "28691333-4650-4eac-b4bf-36c29dbd6f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Landmarks: 63\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracted Landmarks:\", len(landmarks_array[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a1655b-38f8-4e20-8052-95f3c0f81b55",
   "metadata": {},
   "source": [
    "# 4. Training Model with Custom Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4e10e9d-f72c-4100-a222-9e1a80bf5301",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d58a997a-262e-48f6-ac45-96771f845d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, None, None, None), dtype=tf.float32, name='input_6'), name='input_6', description=\"created by layer 'input_6'\")\n",
      "\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 63), dtype=tf.float32, name=None), name='landmarks_detector_v3_5/map/TensorArrayV2Stack/TensorListStack:0', description=\"created by layer 'landmarks_detector_v3_5'\")\n",
      "\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 63), dtype=tf.float32, name=None), name='flatten_3/Reshape:0', description=\"created by layer 'flatten_3'\")\n",
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, None, None, Non   0         \n",
      "                             e)]                                 \n",
      "                                                                 \n",
      " landmarks_detector_v3_5 (L  (None, 63)                0         \n",
      " andmarksDetectorV3)                                             \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 63)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 128)               8192      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 13)                845       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17293 (67.55 KB)\n",
      "Trainable params: 17293 (67.55 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define your DNN model\n",
    "def create_model(num_classes):\n",
    "    inputs = tf.keras.Input(shape=(None, None, None))\n",
    "    print(inputs, end=\"\\n\\n\")\n",
    "    x = LandmarksDetectorV3()(inputs)\n",
    "    print(x, end=\"\\n\\n\")\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    print(x)\n",
    "    x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the model\n",
    "model = create_model(num_classes)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "# Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39f76cad-3611-4fd5-9c38-7e76ffdba2c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode string labels to integer labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "np.unique(y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e8db483-4f1d-405c-ac05-d8fe12427932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Apps\\anaconda\\envs\\swara\\lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 184s 2s/step - loss: 2.4742 - accuracy: 0.1520\n",
      "Epoch 2/10\n",
      "114/114 [==============================] - 184s 2s/step - loss: 2.3177 - accuracy: 0.2348\n",
      "Epoch 3/10\n",
      "114/114 [==============================] - 188s 2s/step - loss: 2.1328 - accuracy: 0.3421\n",
      "Epoch 4/10\n",
      "114/114 [==============================] - 189s 2s/step - loss: 1.9417 - accuracy: 0.4066\n",
      "Epoch 5/10\n",
      "114/114 [==============================] - 190s 2s/step - loss: 1.7833 - accuracy: 0.4508\n",
      "Epoch 6/10\n",
      "114/114 [==============================] - 194s 2s/step - loss: 1.6370 - accuracy: 0.4771\n",
      "Epoch 7/10\n",
      "114/114 [==============================] - 189s 2s/step - loss: 1.5342 - accuracy: 0.5073\n",
      "Epoch 8/10\n",
      "114/114 [==============================] - 188s 2s/step - loss: 1.4341 - accuracy: 0.5202\n",
      "Epoch 9/10\n",
      "114/114 [==============================] - 184s 2s/step - loss: 1.3349 - accuracy: 0.5630\n",
      "Epoch 10/10\n",
      "114/114 [==============================] - 185s 2s/step - loss: 1.2786 - accuracy: 0.5824\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'hands' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(train_images, train_labels, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Don't forget to close the hands instance\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[43mhands\u001b[49m\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hands' is not defined"
     ]
    }
   ],
   "source": [
    "# Assuming you have your dataset and labels prepared\n",
    "train_images = X_train\n",
    "train_labels = y_train_encoded\n",
    "model.fit(train_images, train_labels, epochs=10, batch_size=32)\n",
    "\n",
    "# Don't forget to close the hands instance\n",
    "hands.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9dbeeb71-2c00-4ac6-91b2-794d7c80fe01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Apps\\anaconda\\envs\\swara\\lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 46s 2s/step - loss: 1.2611 - accuracy: 0.5866\n",
      "Test Loss: 1.261136770248413\n",
      "Test Accuracy: 0.5866228342056274\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_test_encoded = label_encoder.fit_transform(y_test)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test_encoded)\n",
    "\n",
    "# Print the test loss and accuracy\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "53aa0b60-9e28-4862-a286-cd7d0cd3ef59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf2onnx\n",
      "  Downloading tf2onnx-1.16.1-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: numpy>=1.14.1 in d:\\apps\\anaconda\\envs\\swara\\lib\\site-packages (from tf2onnx) (1.24.3)\n",
      "Requirement already satisfied: onnx>=1.4.1 in d:\\apps\\anaconda\\envs\\swara\\lib\\site-packages (from tf2onnx) (1.16.1)\n",
      "Requirement already satisfied: requests in d:\\apps\\anaconda\\envs\\swara\\lib\\site-packages (from tf2onnx) (2.32.3)\n",
      "Requirement already satisfied: six in d:\\apps\\anaconda\\envs\\swara\\lib\\site-packages (from tf2onnx) (1.16.0)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in d:\\apps\\anaconda\\envs\\swara\\lib\\site-packages (from tf2onnx) (24.3.25)\n",
      "Requirement already satisfied: protobuf~=3.20 in d:\\apps\\anaconda\\envs\\swara\\lib\\site-packages (from tf2onnx) (3.20.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\apps\\anaconda\\envs\\swara\\lib\\site-packages (from requests->tf2onnx) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\apps\\anaconda\\envs\\swara\\lib\\site-packages (from requests->tf2onnx) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\apps\\anaconda\\envs\\swara\\lib\\site-packages (from requests->tf2onnx) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\apps\\anaconda\\envs\\swara\\lib\\site-packages (from requests->tf2onnx) (2024.6.2)\n",
      "Downloading tf2onnx-1.16.1-py3-none-any.whl (455 kB)\n",
      "   ---------------------------------------- 0.0/455.8 kB ? eta -:--:--\n",
      "   -------- ------------------------------- 92.2/455.8 kB 2.6 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 92.2/455.8 kB 2.6 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 225.3/455.8 kB 1.7 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 225.3/455.8 kB 1.7 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 245.8/455.8 kB 1.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 307.2/455.8 kB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 358.4/455.8 kB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 389.1/455.8 kB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 455.8/455.8 kB 1.1 MB/s eta 0:00:00\n",
      "Installing collected packages: tf2onnx\n",
      "Successfully installed tf2onnx-1.16.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\asus tuf\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\asus tuf\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\asus tuf\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\asus tuf\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\asus tuf\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\asus tuf\\appdata\\roaming\\python\\python39\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install tf2onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3023b04d-ec47-4aff-9cc4-5b7709aed7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Handsign_detection\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Handsign_detection\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('Handsign_detection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93b621c-e13c-4f49-bbc0-9f55e39b72d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
